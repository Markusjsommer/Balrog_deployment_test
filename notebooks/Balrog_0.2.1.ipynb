{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Balrog_0.2.1.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm","mount_file_id":"1rAQd-UsKhliEHw_tDMGv2a_UMS4iPA3V","authorship_tag":"ABX9TyMO9AoEXnPRnxP3LNT6GAvP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"6SYiIHRhZM-m","colab_type":"text"},"source":["# Google Colab Intro\n","#### This notebook downloads data and performs computations. These computations are made significantly faster with the use of a GPU, provided free by Google as part of Colab.\n","\n","#### Press the play button on the left side of each cell to run it. Alternatively, hold shift or ctrl and press enter to run cells.\n","#### Double click a cell to inspect the code inside and change things.\n","#### Have fun!\n","\n","#### (note: this project is meant to be a proof of concept, not a drop in replacement for a well-optimized gene finder. A faster C++ version will probably be released at some point if it seems like that would be useful)"]},{"cell_type":"markdown","metadata":{"id":"aEszqvakZN9C","colab_type":"text"},"source":["# Setup"]},{"cell_type":"code","metadata":{"id":"VMJQa6JAXDf_","colab_type":"code","cellView":"form","outputId":"a97d174d-f257-4c23-c806-c0cd218946e0","executionInfo":{"status":"ok","timestamp":1591065973695,"user_tz":240,"elapsed":6458,"user":{"displayName":"Markus Sommer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXujbpCzD6oVvcRIT5EP-oi3Bif3Cfcu7npJUnce8=s64","userId":"08083804319459268544"}},"colab":{"base_uri":"https://localhost:8080/","height":136}},"source":["# @title Install dependencies\n","!pip install biopython\n","!pip install torch\n","print(\"\\nDone\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: biopython in /usr/local/lib/python3.6/dist-packages (1.77)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from biopython) (1.18.4)\n","Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.5.0+cu101)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.18.4)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch) (0.16.0)\n","\n","Done\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pe1PHlcjeHS8","colab_type":"code","cellView":"form","outputId":"8c844559-2e5a-48f7-f4f7-74a90ce82e9b","executionInfo":{"status":"ok","timestamp":1591065973697,"user_tz":240,"elapsed":6000,"user":{"displayName":"Markus Sommer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXujbpCzD6oVvcRIT5EP-oi3Bif3Cfcu7npJUnce8=s64","userId":"08083804319459268544"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# @title Import python packages\n","import os\n","import gzip\n","import copy\n","import time\n","import pandas\n","import pickle\n","import numpy as np\n","from tqdm.auto import tqdm\n","from Bio import SeqIO\n","from scipy.special import expit\n","from scipy.special import logit\n","import networkx as nx\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.nn.utils import weight_norm\n","\n","print(\"Done\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Done\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"usWmfqJNhM2X","colab_type":"code","cellView":"form","outputId":"f3417dc7-ed1a-4038-970a-35dd18194dc4","executionInfo":{"status":"ok","timestamp":1591065973699,"user_tz":240,"elapsed":4347,"user":{"displayName":"Markus Sommer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXujbpCzD6oVvcRIT5EP-oi3Bif3Cfcu7npJUnce8=s64","userId":"08083804319459268544"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# @title Set parameters (double click here to change defaults)\n","\"\"\" Print what the program is doing.\"\"\"\n","verbose = True\n","\n","\"\"\" Maximum ORF (open reading frame) overlap length in nucleotides.\"\"\"\n","max_gene_overlap = 60\n","\n","\"\"\" Minimum ORF length in nucleotides.\"\"\"\n","min_orf_length = 100\n","\n","\"\"\" Use mmseqs2 and a gene score cutoff to remove most false positive predictions.\"\"\"\n","filter_gene_predictions = True\n","\n","\"\"\" Use kmer prefilter to increase gene sensitivity. \n","May not play nice with high GC genomes.\"\"\"\n","filter_kmer = True\n","\n","\"\"\" Nucleotide to amino acid translation table. 11 for most bacteria/archaea.\n","4 for Mycoplasma/Spiroplasma. Can be 1 to 25.\"\"\"\n","translation_table = 11\n","\n","\"\"\" Maximum number of forward connections in the directed acyclic graph used to\n","find a set of coherent genes in each genome.\n","Higher values will slow execution time but may slightly increase performace.\n","Recommended range 30 to 100.\"\"\"\n","max_forward_connections = 50\n","\n","\"\"\" Batch size for the temporal convolutional network used to score genes.\n","Small batches and big batches slow down the model. Very big batches may crash the \n","GPU. \"\"\"\n","gene_batch_size = 3000\n","\n","\"\"\" Where the pre-trained gene model should be saved.\"\"\"\n","model_dir = \"/home\"\n","\n","\n","\"\"\" All following are internal parameters. Change at your own risk.\"\"\"\n","weight_gene_prob = 0.9746869839852076 \n","weight_TIS_prob = 0.25380288790532707 \n","score_threshold = 0.47256101519707244\n","weight_ATG = 0.84249804151264 \n","weight_GTG = 0.7083689705744909\n","weight_TTG = 0.7512400826652517 \n","unidirectional_penalty_per_base = 3.895921717182765 # 3' 5' overlap\n","convergent_penalty_per_base = 4.603432608883688 # 3' 3' overlap\n","divergent_penalty_per_base = 3.3830814940689975 # 5' 5' overlap\n","\n","k_seengene = 10\n","multimer_threshold = 2\n","\n","\n","# weight_gene_prob = 0.9746869839852076 \n","# weight_TIS_prob = 0.25380288790532707 \n","# score_threshold = 0.47256101519707244\n","# weight_ATG = 0.84\n","# weight_GTG = 0.14\n","# weight_TTG = 0.03 \n","# unidirectional_penalty_per_base = 3 # 3' 5' overlap\n","# convergent_penalty_per_base = 3 # 3' 3' overlap\n","# divergent_penalty_per_base = 5 # 5' 5' overlap\n","\n","# weight_gene_prob = 0.9578349986086553 \n","# weight_TIS_prob = 0.5144895885507309 \n","# score_threshold = 0.18612804507042569\n","# weight_ATG = 0.6958167545680435 \n","# weight_GTG = 0.5112666591536028\n","# weight_TTG = 0.5372931869382979 \n","# unidirectional_penalty_per_base = 2.7082978223323337 # 3' 5' overlap\n","# convergent_penalty_per_base = 9.28139793016752 # 3' 3' overlap\n","# divergent_penalty_per_base = 0.7174449102593538 # 5' 5' overlap\n","\n","print(\"Done\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Done\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"idOvBwhe0NtP","colab_type":"code","cellView":"form","outputId":"32cbaabc-9d3a-49a0-a7cc-daebb64f7e03","executionInfo":{"status":"ok","timestamp":1591065983133,"user_tz":240,"elapsed":12666,"user":{"displayName":"Markus Sommer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXujbpCzD6oVvcRIT5EP-oi3Bif3Cfcu7npJUnce8=s64","userId":"08083804319459268544"}},"colab":{"base_uri":"https://localhost:8080/","height":102}},"source":["# @title Load pre-trained gene and translation initiation site models\n","\n","\"\"\" if you're interested in the inner workings of the \n","temporal convolutional network, see hubconf.py in the Github repo below.\"\"\"\n","\n","repo = \"Markusjsommer/test_TCN\"\n","\n","torch.hub.set_dir(model_dir)\n","if torch.cuda.device_count() > 0:\n","    print(\"GPU detected...\")\n","    model = torch.hub.load(repo, \"geneTCN\", force_reload=True).cuda()\n","    model_tis = torch.hub.load(repo, \"tisTCN\", force_reload=False).cuda()\n","    time.sleep(0.5)\n","    print(\"\\nDone\")\n","else:\n","    print(\"No GPU detected, using CPU...\")\n","    model = torch.hub.load(repo, \"geneTCN\", force_reload=True)\n","    model_tis = torch.hub.load(repo, \"tisTCN\", force_reload=False)\n","    time.sleep(0.5)\n","    print(\"\\nDone\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["GPU detected...\n"],"name":"stdout"},{"output_type":"stream","text":["Downloading: \"https://github.com/Markusjsommer/test_TCN/archive/master.zip\" to /home/master.zip\n","Using cache found in /home/Markusjsommer_test_TCN_master\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Done\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RH9tYuV6CYax","colab_type":"code","colab":{}},"source":["#TODO change /home/Markusjsommer_test_TCN_master to match parameter model download dir"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wQMPFNbdk8vv","colab_type":"code","cellView":"form","outputId":"ebec6e39-8e03-4127-b324-aa8e78741e45","executionInfo":{"status":"ok","timestamp":1591065989399,"user_tz":240,"elapsed":17465,"user":{"displayName":"Markus Sommer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXujbpCzD6oVvcRIT5EP-oi3Bif3Cfcu7npJUnce8=s64","userId":"08083804319459268544"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["# @title Prepare kmer-based prefilter\n","if filter_kmer:\n","    # decompress kmer filter\n","    seengene_dir = \"/content/seengene/\"\n","    !mkdir {seengene_dir}\n","    %cd {seengene_dir}\n","    !!tar -xvzf /home/Markusjsommer_test_TCN_master/kmer_filter/genexa_10mer_thresh2_minusARF_all.tar.gz\n","    genexa_kmer_path = os.path.join(seengene_dir, \"10mer_thresh2_minusARF_all.pkl\")\n","\n","    # load kmer filter\n","    with open(genexa_kmer_path, \"rb\") as f:\n","        aa_kmer_set = pickle.load(f)\n","\n","print(\"\\nDone\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["mkdir: cannot create directory ‘/content/seengene/’: File exists\n","/content/seengene\n","\n","Done\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"p3jzwdcGp7XN","colab_type":"code","cellView":"form","outputId":"13529077-b94a-4b57-dc27-601e3548c33e","executionInfo":{"status":"ok","timestamp":1591066057208,"user_tz":240,"elapsed":84515,"user":{"displayName":"Markus Sommer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXujbpCzD6oVvcRIT5EP-oi3Bif3Cfcu7npJUnce8=s64","userId":"08083804319459268544"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# @title Prepare mmseqs2 (will be skipped if gene prediction filter option is set to False)\n","\n","if filter_gene_predictions:\n","    ![ $(uname -m) = \"x86_64\" ] && echo \"64bit: Yes\" || echo \"64bit: No\"\n","    !grep -q sse4_1 /proc/cpuinfo && echo \"SSE4.1: Yes\" || echo \"SSE4.1: No\"\n","    !grep -q avx2 /proc/cpuinfo && echo \"AVX2: Yes\" || echo \"AVX2: No\"\n","\n","    # install\n","    !mkdir /content/mmseqs2\n","    %cd /content/mmseqs2\n","    !wget https://mmseqs.com/latest/mmseqs-linux-avx2.tar.gz\n","    !tar xvzf mmseqs-linux-avx2.tar.gz\n","\n","    # decompress fasta\n","    !mkdir /content/mmseqs2/genexa\n","    %cd /content/mmseqs2/genexa\n","    !!tar -xvzf /home/Markusjsommer_test_TCN_master/protein_filter/genexa_genes.tar.gz\n","    genexa_fasta_path = \"/content/mmseqs2/genexa/genexa_genes.fasta\"\n","\n","    # create DB\n","    genexa_DB_path = \"/content/mmseqs2/genexa/genexaDB\"\n","    !/content/mmseqs2/mmseqs/bin/mmseqs createdb {genexa_fasta_path} {genexa_DB_path}\n","\n","    # build mmseqs index\n","    !mkdir /content/mmseqs2/tmp\n","    !/content/mmseqs2/mmseqs/bin/mmseqs createindex {genexa_DB_path} /content/mmseqs2/tmp\n","\n","print(\"\\nDone\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["64bit: Yes\n","SSE4.1: Yes\n","AVX2: Yes\n","mkdir: cannot create directory ‘/content/mmseqs2’: File exists\n","/content/mmseqs2\n","--2020-06-02 02:46:30--  https://mmseqs.com/latest/mmseqs-linux-avx2.tar.gz\n","Resolving mmseqs.com (mmseqs.com)... 141.5.100.26\n","Connecting to mmseqs.com (mmseqs.com)|141.5.100.26|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 27003888 (26M) [application/octet-stream]\n","Saving to: ‘mmseqs-linux-avx2.tar.gz.1’\n","\n","mmseqs-linux-avx2.t 100%[===================>]  25.75M  12.7MB/s    in 2.0s    \n","\n","2020-06-02 02:46:33 (12.7 MB/s) - ‘mmseqs-linux-avx2.tar.gz.1’ saved [27003888/27003888]\n","\n","mmseqs/\n","mmseqs/userguide.pdf\n","mmseqs/matrices/\n","mmseqs/matrices/PAM40.out\n","mmseqs/matrices/PAM70.out\n","mmseqs/matrices/PAM50.out\n","mmseqs/matrices/PAM30.out\n","mmseqs/matrices/PAM120.out\n","mmseqs/matrices/PAM80.out\n","mmseqs/matrices/PAM150.out\n","mmseqs/matrices/blosum85.out\n","mmseqs/matrices/VTML120.out\n","mmseqs/matrices/PAM110.out\n","mmseqs/matrices/PAM140.out\n","mmseqs/matrices/blosum35.out\n","mmseqs/matrices/VTML40.out\n","mmseqs/matrices/blosum70.out\n","mmseqs/matrices/PAM90.out\n","mmseqs/matrices/PAM170.out\n","mmseqs/matrices/PAM60.out\n","mmseqs/matrices/blosum30.out\n","mmseqs/matrices/blosum60.out\n","mmseqs/matrices/blosum80.out\n","mmseqs/matrices/VTML10.out\n","mmseqs/matrices/PAM190.out\n","mmseqs/matrices/blosum95.out\n","mmseqs/matrices/PAM180.out\n","mmseqs/matrices/blosum50.out\n","mmseqs/matrices/PAM160.out\n","mmseqs/matrices/PAM100.out\n","mmseqs/matrices/PAM130.out\n","mmseqs/matrices/blosum45.out\n","mmseqs/matrices/PAM10.out\n","mmseqs/matrices/blosum62.out\n","mmseqs/matrices/blosum40.out\n","mmseqs/matrices/blosum100.out\n","mmseqs/matrices/blosum65.out\n","mmseqs/matrices/nucleotide.out\n","mmseqs/matrices/VTML80.out\n","mmseqs/matrices/blosum90.out\n","mmseqs/matrices/VTML160.out\n","mmseqs/matrices/VTML20.out\n","mmseqs/matrices/blosum75.out\n","mmseqs/matrices/PAM20.out\n","mmseqs/matrices/blosum55.out\n","mmseqs/examples/\n","mmseqs/examples/QUERY.fasta\n","mmseqs/examples/DB.fasta\n","mmseqs/bin/\n","mmseqs/bin/mmseqs\n","mmseqs/LICENCE.md\n","mmseqs/util/\n","mmseqs/util/bash-completion.sh\n","mmseqs/README.md\n","mkdir: cannot create directory ‘/content/mmseqs2/genexa’: File exists\n","/content/mmseqs2/genexa\n","\u001b[33m/content/mmseqs2/genexa/genexaDB exists and will be overwritten.\n","\u001b[39mcreatedb /content/mmseqs2/genexa/genexa_genes.fasta /content/mmseqs2/genexa/genexaDB \n","\n","MMseqs Version:       \t128f57b5d7a16ae57a7f7b497224f951936a0b35\n","Database type         \t0\n","Shuffle input database\ttrue\n","Createdb mode         \t0\n","Write lookup file     \t1\n","Offset of numeric ids \t0\n","Compressed            \t0\n","Verbosity             \t3\n","\n","Converting sequences\n","[468338] 0s 828ms\n","Time for merging to genexaDB_h: 0h 0m 0s 157ms\n","Time for merging to genexaDB: 0h 0m 0s 435ms\n","Database type: Aminoacid\n","Time for merging to genexaDB.lookup: 0h 0m 0s 0ms\n","Time for processing: 0h 0m 2s 74ms\n","mkdir: cannot create directory ‘/content/mmseqs2/tmp’: File exists\n","createindex /content/mmseqs2/genexa/genexaDB /content/mmseqs2/tmp \n","\n","MMseqs Version:          \t128f57b5d7a16ae57a7f7b497224f951936a0b35\n","Seed substitution matrix \tnucl:nucleotide.out,aa:VTML80.out\n","k-mer length             \t0\n","Alphabet size            \tnucl:5,aa:21\n","Compositional bias       \t1\n","Max sequence length      \t65535\n","Max results per query    \t300\n","Mask residues            \t1\n","Mask lower case residues \t0\n","Spaced k-mers            \t1\n","Spaced k-mer pattern     \t\n","Sensitivity              \t7.5\n","k-score                  \t0\n","Check compatible         \t0\n","Search type              \t0\n","Split database           \t0\n","Split memory limit       \t0\n","Verbosity                \t3\n","Threads                  \t4\n","Min codons in orf        \t30\n","Max codons in length     \t32734\n","Max orf gaps             \t2147483647\n","Contig start mode        \t2\n","Contig end mode          \t2\n","Orf start mode           \t1\n","Forward frames           \t1,2,3\n","Reverse frames           \t1,2,3\n","Translation table        \t1\n","Translate orf            \t0\n","Use all table starts     \tfalse\n","Offset of numeric ids    \t0\n","Create lookup            \t0\n","Compressed               \t0\n","Add orf stop             \tfalse\n","Overlap between sequences\t0\n","Sequence split mode      \t1\n","Strand selection         \t1\n","Remove temporary files   \tfalse\n","\n","createindex /content/mmseqs2/genexa/genexaDB /content/mmseqs2/tmp \n","\n","MMseqs Version:          \t128f57b5d7a16ae57a7f7b497224f951936a0b35\n","Seed substitution matrix \tnucl:nucleotide.out,aa:VTML80.out\n","k-mer length             \t0\n","Alphabet size            \tnucl:5,aa:21\n","Compositional bias       \t1\n","Max sequence length      \t65535\n","Max results per query    \t300\n","Mask residues            \t1\n","Mask lower case residues \t0\n","Spaced k-mers            \t1\n","Spaced k-mer pattern     \t\n","Sensitivity              \t7.5\n","k-score                  \t0\n","Check compatible         \t0\n","Search type              \t0\n","Split database           \t0\n","Split memory limit       \t0\n","Verbosity                \t3\n","Threads                  \t4\n","Min codons in orf        \t30\n","Max codons in length     \t32734\n","Max orf gaps             \t2147483647\n","Contig start mode        \t2\n","Contig end mode          \t2\n","Orf start mode           \t1\n","Forward frames           \t1,2,3\n","Reverse frames           \t1,2,3\n","Translation table        \t1\n","Translate orf            \t0\n","Use all table starts     \tfalse\n","Offset of numeric ids    \t0\n","Create lookup            \t0\n","Compressed               \t0\n","Add orf stop             \tfalse\n","Overlap between sequences\t0\n","Sequence split mode      \t1\n","Strand selection         \t1\n","Remove temporary files   \tfalse\n","\n","indexdb /content/mmseqs2/genexa/genexaDB /content/mmseqs2/genexa/genexaDB --seed-sub-mat nucl:nucleotide.out,aa:VTML80.out -k 0 --alph-size nucl:5,aa:21 --comp-bias-corr 1 --max-seq-len 65535 --max-seqs 300 --mask 1 --mask-lower-case 0 --spaced-kmer-mode 1 -s 7.5 --k-score 0 --check-compatible 0 --search-type 0 --split 0 --split-memory-limit 0 -v 3 --threads 4 \n","\n","Estimated memory consumption: 2G\n","Write VERSION (0)\n","Write META (1)\n","Write SCOREMATRIX3MER (4)\n","Write SCOREMATRIX2MER (3)\n","Write SCOREMATRIXNAME (2)\n","Write SPACEDPATTERN (23)\n","Write DBR1INDEX (5)\n","Write DBR1DATA (6)\n","Write HDR1INDEX (18)\n","Write HDR1DATA (19)\n","Write GENERATOR (22)\n","Index table: counting k-mers\n","[=================================================================] 100.00% 468.35K 23s 890ms\n","Index table: Masked residues: 931982\n","Index table: fill\n","[=================================================================] 100.00% 468.35K 16s 928ms\n","Index statistics\n","Entries:          155110361\n","DB size:          1375 MB\n","Avg k-mer size:   2.423599\n","Top 10 k-mers\n","    TSGGGV\t2599\n","    RAARQG\t2269\n","    TSGGGI\t1980\n","    AVQQSL\t1945\n","    RLTKGS\t1733\n","    TTGGGV\t1443\n","    LAAAQQ\t896\n","    IARQGS\t831\n","    ALREVV\t810\n","    TSGGGT\t772\n","Write ENTRIES (9)\n","Write ENTRIESOFFSETS (10)\n","Write SEQINDEXDATASIZE (15)\n","Write SEQINDEXSEQOFFSET (16)\n","Write SEQINDEXDATA (14)\n","Write ENTRIESNUM (12)\n","Write SEQCOUNT (13)\n","Time for merging to genexaDB.idx: 0h 0m 0s 0ms\n","Time for processing: 0h 0m 50s 120ms\n","\n","Done\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pT8CEPxlwhGl","colab_type":"code","outputId":"6944d532-f5f6-47ad-9b7c-4b6e03c970f9","executionInfo":{"status":"ok","timestamp":1591066076632,"user_tz":240,"elapsed":102485,"user":{"displayName":"Markus Sommer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXujbpCzD6oVvcRIT5EP-oi3Bif3Cfcu7npJUnce8=s64","userId":"08083804319459268544"}},"colab":{"base_uri":"https://localhost:8080/","height":306}},"source":["!mkdir /content/mmseqs2/swissprot\n","!/content/mmseqs2/mmseqs/bin/mmseqs databases UniProtKB/Swiss-Prot /content/mmseqs2/swissprot/swissprotDB /content/mmseqs2/tmp"],"execution_count":0,"outputs":[{"output_type":"stream","text":["mkdir: cannot create directory ‘/content/mmseqs2/swissprot’: File exists\n","\u001b[33m/content/mmseqs2/swissprot/swissprotDB exists and will be overwritten.\n","\u001b[39mdatabases UniProtKB/Swiss-Prot /content/mmseqs2/swissprot/swissprotDB /content/mmseqs2/tmp \n","\n","MMseqs Version:              \t128f57b5d7a16ae57a7f7b497224f951936a0b35\n","Force restart with latest tmp\tfalse\n","Remove temporary files       \tfalse\n","Compressed                   \t0\n","Threads                      \t4\n","Verbosity                    \t3\n","\n","  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100   151  100   151    0     0    131      0  0:00:01  0:00:01 --:--:--   131\n","  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100 85.1M  100 85.1M    0     0  9981k      0  0:00:08  0:00:08 --:--:-- 18.2M\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-o5NOo_WzKKM","colab_type":"code","colab":{}},"source":["swissprot_DB_path = \"/content/mmseqs2/swissprot/swissprotDB\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"L1Bb2cDq2jMT","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"774k0Hiz2jIz","colab_type":"code","outputId":"adef8a5b-8fcc-4972-830c-59cbf2ff7fec","executionInfo":{"status":"ok","timestamp":1590954151059,"user_tz":240,"elapsed":7799,"user":{"displayName":"Markus Sommer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXujbpCzD6oVvcRIT5EP-oi3Bif3Cfcu7npJUnce8=s64","userId":"08083804319459268544"}},"colab":{"base_uri":"https://localhost:8080/","height":374}},"source":["!mkdir /content/mmseqs2/PDB\n","!/content/mmseqs2/mmseqs/bin/mmseqs databases PDB /content/mmseqs2/PDB/PDB /content/mmseqs2/tmp"],"execution_count":0,"outputs":[{"output_type":"stream","text":["databases PDB /content/mmseqs2/PDB/PDB /content/mmseqs2/tmp \n","\n","MMseqs Version:              \t128f57b5d7a16ae57a7f7b497224f951936a0b35\n","Force restart with latest tmp\tfalse\n","Remove temporary files       \tfalse\n","Compressed                   \t0\n","Threads                      \t4\n","Verbosity                    \t3\n","\n","  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100 29.7M  100 29.7M    0     0  13.4M      0  0:00:02  0:00:02 --:--:-- 13.4M\n","createdb /content/mmseqs2/tmp/14291463772269900986/pdb_seqres.txt.gz /content/mmseqs2/PDB/PDB --compressed 0 -v 3 \n","\n","Converting sequences\n","[554895] 1s 597ms\n","Time for merging to PDB_h: 0h 0m 0s 222ms\n","Time for merging to PDB: 0h 0m 1s 446ms\n","Database type: Aminoacid\n","Time for merging to PDB.lookup: 0h 0m 0s 0ms\n","Time for processing: 0h 0m 3s 963ms\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"eQugjbpf2jGb","colab_type":"code","colab":{}},"source":["UniRef50_DB_path = \"/content/mmseqs2/PDB/PDB\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QiXUEN7NVuTD","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fmJ8y8FMQ4R7","colab_type":"code","outputId":"c2a511b7-adf4-4a6f-cba6-7603187590fa","executionInfo":{"status":"ok","timestamp":1590956587258,"user_tz":240,"elapsed":293,"user":{"displayName":"Markus Sommer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXujbpCzD6oVvcRIT5EP-oi3Bif3Cfcu7npJUnce8=s64","userId":"08083804319459268544"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QOLkpzzDQ7NQ","colab_type":"code","outputId":"e4eadd6a-0f4a-4272-cdd4-7b94998e7c35","colab":{"base_uri":"https://localhost:8080/","height":335}},"source":["!/content/mmseqs2/mmseqs/bin/mmseqs databases UniRef50 \"/content/drive/My Drive/mmseqs/UniRef50\" \"/content/mmseqs2/tmp/tmp\" --remove-tmp-files --compressed 1"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\u001b[33m/content/drive/My Drive/mmseqs/UniRef50 exists and will be overwritten.\n","\u001b[39m\u001b[33mTmp /content/mmseqs2/tmp/tmp folder does not exist or is not a directory.\n","\u001b[39mCreate dir /content/mmseqs2/tmp/tmp\n","databases UniRef50 /content/drive/My Drive/mmseqs/UniRef50 /content/mmseqs2/tmp/tmp --remove-tmp-files --compressed 1 \n","\n","MMseqs Version:              \t128f57b5d7a16ae57a7f7b497224f951936a0b35\n","Force restart with latest tmp\tfalse\n","Remove temporary files       \ttrue\n","Compressed                   \t1\n","Threads                      \t4\n","Verbosity                    \t3\n","\n","  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100   310  100   310    0     0    108      0  0:00:02  0:00:02 --:--:--   108\n","  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","  1 7803M    1 97.5M    0     0  1480k      0  1:29:57  0:01:07  1:28:50 3462k"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"A7ZE2TBcQ7K7","colab_type":"code","colab":{}},"source":["UniRef50_DB_path = \"/content/mmseqs2/UniRef50/UniRef50\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JFfKsI7CREB2","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YYEqpFU1ZWJy","colab_type":"code","outputId":"39461352-6aad-4c38-c9c1-1a3b2ccfdd3b","executionInfo":{"status":"ok","timestamp":1590985077775,"user_tz":240,"elapsed":174434,"user":{"displayName":"Markus Sommer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXujbpCzD6oVvcRIT5EP-oi3Bif3Cfcu7npJUnce8=s64","userId":"08083804319459268544"}},"colab":{"base_uri":"https://localhost:8080/","height":510}},"source":["# profile\n","!mkdir /content/mmseqs2/Pfam-A\n","!/content/mmseqs2/mmseqs/bin/mmseqs databases Pfam-A.seed /content/mmseqs2/Pfam-A/Pfam-A /content/mmseqs2/tmp"],"execution_count":0,"outputs":[{"output_type":"stream","text":["databases Pfam-A.seed /content/mmseqs2/Pfam-A/Pfam-A /content/mmseqs2/tmp \n","\n","MMseqs Version:              \t128f57b5d7a16ae57a7f7b497224f951936a0b35\n","Force restart with latest tmp\tfalse\n","Remove temporary files       \tfalse\n","Compressed                   \t0\n","Threads                      \t4\n","Verbosity                    \t3\n","\n","  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100   114  100   114    0     0     58      0  0:00:01  0:00:01 --:--:--    58\n","  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100  155M  100  155M    0     0  19.7M      0  0:00:07  0:00:07 --:--:-- 27.9M\n","convertmsa /content/mmseqs2/tmp/11012549394282118771/db.msa.gz /content/mmseqs2/tmp/11012549394282118771/msa -v 3 \n","\n","Time for merging to msa: 0h 0m 5s 944ms\n","Time for processing: 0h 0m 14s 505ms\n","msa2profile /content/mmseqs2/tmp/11012549394282118771/msa /content/mmseqs2/Pfam-A/Pfam-A --match-mode 1 --match-ratio 0.5 --threads 4 -v 3 \n","\n","Finding maximum sequence length and set size.\n","[=================================================================] 100.00% 17.93K 38s 277ms\n","Time for merging to Pfam-A_h: 0h 0m 0s 6ms\n","Time for merging to Pfam-A: 0h 0m 0s 83ms\n","Time for processing: 0h 0m 38s 842ms\n","rmdb /content/mmseqs2/tmp/11012549394282118771/msa \n","\n","Time for processing: 0h 0m 0s 39ms\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Pnh2_aAJZWG9","colab_type":"code","colab":{}},"source":["Pfam_DB_path = \"/content/mmseqs2/Pfam-A/Pfam-A\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pk0SMnbkZWEz","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NFGHIQZ6RD55","colab_type":"code","outputId":"ab6d88fb-7e8f-4fb0-8790-a15fdc52f0fc","executionInfo":{"status":"ok","timestamp":1590956219625,"user_tz":240,"elapsed":2841,"user":{"displayName":"Markus Sommer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXujbpCzD6oVvcRIT5EP-oi3Bif3Cfcu7npJUnce8=s64","userId":"08083804319459268544"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!/content/mmseqs2/mmseqs/bin/mmseqs databases  -h"],"execution_count":0,"outputs":[{"output_type":"stream","text":["usage: mmseqs databases <name> <o:sequenceDB> <tmpDir> [options]\n"," By Milot Mirdita <milot@mirdita.de>\n","\n","  Name                \tType      \tTaxonomy\tUrl                                        \n","- UniRef100           \tAminoacid \t     yes\thttps://www.uniprot.org/help/uniref        \n","  The UniProt Reference Clusters provide clustered sets of sequences from the UniProt Knowledgebase.\n","  Cite: Suzek et al: UniRef: comprehensive and non-redundant UniProt reference clusters. Bioinformatics 23(10), 1282–1288 (2007)\n","- UniRef90            \tAminoacid \t     yes\thttps://www.uniprot.org/help/uniref        \n","  The UniProt Reference Clusters provide clustered sets of sequences from the UniProt Knowledgebase.\n","  Cite: Suzek et al: UniRef: comprehensive and non-redundant UniProt reference clusters. Bioinformatics 23(10), 1282–1288 (2007)\n","- UniRef50            \tAminoacid \t     yes\thttps://www.uniprot.org/help/uniref        \n","  The UniProt Reference Clusters provide clustered sets of sequences from the UniProt Knowledgebase.\n","  Cite: Suzek et al: UniRef: comprehensive and non-redundant UniProt reference clusters. Bioinformatics 23(10), 1282–1288 (2007)\n","- UniProtKB           \tAminoacid \t     yes\thttps://www.uniprot.org/help/uniprotkb     \n","  The UniProt Knowledgebase is the central hub for the collection of functional information on proteins, with accurate, consistent and rich annotation.\n","  Cite: The UniProt Consortium: UniProt: a worldwide hub of protein knowledge. Nucleic Acids Res 47(D1), D506-515 (2019)\n","- UniProtKB/TrEMBL    \tAminoacid \t     yes\thttps://www.uniprot.org/help/uniprotkb     \n","  UniProtKB/TrEMBL (unreviewed) contains protein sequences associated with computationally generated annotation and large-scale functional characterization.\n","  Cite: The UniProt Consortium: UniProt: a worldwide hub of protein knowledge. Nucleic Acids Res 47(D1), D506-515 (2019)\n","- UniProtKB/Swiss-Prot\tAminoacid \t     yes\thttps://uniprot.org                        \n","  UniProtKB/Swiss-Prot (reviewed) is a high quality manually annotated and non-redundant protein sequence database, which brings together experimental results, computed features and scientific conclusions.\n","  Cite: The UniProt Consortium: UniProt: a worldwide hub of protein knowledge. Nucleic Acids Res 47(D1), D506-515 (2019)\n","- NR                  \tAminoacid \t       -\thttps://ftp.ncbi.nlm.nih.gov/blast/db/FASTA\n","  Non-redundant protein sequences from GenPept, Swissprot, PIR, PDF, PDB, and NCBI RefSeq.\n","  Cite: NCBI Resource Coordinators: Database resources of the National Center for Biotechnology Information. Nucleic Acids Res 46(D1), D8-D13 (2018)\n","- NT                  \tNucleotide\t       -\thttps://ftp.ncbi.nlm.nih.gov/blast/db/FASTA\n","  Partially non-redundant nucleotide sequences from all traditional divisions of GenBank, EMBL, and DDBJ excluding GSS, STS, PAT, EST, HTG, and WGS.\n","  Cite: NCBI Resource Coordinators: Database resources of the National Center for Biotechnology Information. Nucleic Acids Res 46(D1), D8-D13 (2018)\n","- PDB                 \tAminoacid \t       -\thttps://www.rcsb.org                       \n","  The Protein Data Bank is the single worldwide archive of structural data of biological macromolecules.\n","  Cite: Berman et al: The Protein Data Bank. Nucleic Acids Res 28(1), 235-242 (2000)\n","- PDB70               \tProfile   \t       -\thttps://github.com/soedinglab/hh-suite     \n","  PDB clustered to 70% sequence identity and enriched using HHblits with Uniclust sequences.\n","  Cite: Steinegger et al: HH-suite3 for fast remote homology detection and deep protein annotation. BMC Bioinform 20(1), 473 (2019)\n","- Pfam-A.full         \tProfile   \t       -\thttps://pfam.xfam.org                      \n","  The Pfam database is a large collection of protein families, each represented by multiple sequence alignments and hidden Markov models.\n","  Cite: El-Gebali and Mistry et al: The Pfam protein families database in 2019. Nucleic Acids Res 47(D1), D427-D432 (2019)\n","- Pfam-A.seed         \tProfile   \t       -\thttps://pfam.xfam.org                      \n","  The Pfam database is a large collection of protein families, each represented by multiple sequence alignments and hidden Markov models.\n","  Cite: El-Gebali and Mistry et al: The Pfam protein families database in 2019. Nucleic Acids Res 47(D1), D427-D432 (2019)\n","- eggNOG              \tProfile   \t       -\thttp://eggnog5.embl.de                     \n","  eggNOG is a hierarchical, functionally and phylogenetically annotated orthology resource\n","  Cite: Huerta-Cepas et al: eggNOG 5.0: a hierarchical, functionally and phylogenetically annotated orthology resource based on 5090 organisms and 2502 viruses. Nucleic Acids Res 47(D1), D309–D314 (2019)\n","- Resfinder           \tNucleotide\t       -\thttps://cge.cbs.dtu.dk/services/ResFinder  \n","  ResFinder is a database that captures antimicrobial resistance genes from whole-genome data sets.\n","  Cite: Zankari et al: Identification of acquired antimicrobial resistance genes. J Antimicrob Chemother 67(11), 2640-2644 (2012)\n","- Kalamari            \tNucleotide\t     yes\thttps://github.com/lskatz/Kalamari         \n","  Kalamari contains over 250 genomes chosen to be representative of agents tracked by genome-based foodborne disease surveillance, common contaminants, and diverse phyla and bacterial genera.\n","  Cite: Katz et al: Kraken with Kalamari: Contamination Detection. ASM Poster, 270 (2018)\n","options:                         \n"," --force-reuse BOOL       Reuse tmp filse in tmp/latest folder ignoring parameters and version changes [0]\n"," --remove-tmp-files BOOL  Delete temporary files [0]\n"," --compressed INT         Write compressed output [0]\n"," --threads INT            Number of CPU-cores used (all by default) [4]\n"," -v INT                   Verbosity level: 0: quiet, 1: +errors, 2: +warnings, 3: +info [3]\n","\n","references:\n"," - Steinegger M, Soding J: MMseqs2 enables sensitive protein sequence searching for the analysis of massive data sets. Nature Biotechnology, 35(11), 1026-1028 (2017)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"1Ea6jrhpfF4y","colab_type":"text"},"source":["# Gene Prediction"]},{"cell_type":"code","metadata":{"id":"uh274cXnWlva","colab_type":"code","cellView":"form","outputId":"6e0f2287-6b6a-4b49-d767-823734b896c6","executionInfo":{"status":"ok","timestamp":1591066091410,"user_tz":240,"elapsed":6561,"user":{"displayName":"Markus Sommer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXujbpCzD6oVvcRIT5EP-oi3Bif3Cfcu7npJUnce8=s64","userId":"08083804319459268544"}},"colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":74}},"source":["# @title Upload bacterial genomes as FASTA or gzipped FASTA.\n","from google.colab import files\n","genome_dict = files.upload()"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-97c168c9-c054-409b-bdf2-5b7137df22e3\" name=\"files[]\" multiple disabled />\n","     <output id=\"result-97c168c9-c054-409b-bdf2-5b7137df22e3\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Saving GCF_900465355.1_Ran1-1_genomic.fna.gz to GCF_900465355.1_Ran1-1_genomic.fna (1).gz\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NC4llyrGWIuK","colab_type":"code","cellView":"both","outputId":"4c359f9a-66f1-45c4-bb83-73df1796928f","executionInfo":{"status":"error","timestamp":1591066123122,"user_tz":240,"elapsed":18178,"user":{"displayName":"Markus Sommer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXujbpCzD6oVvcRIT5EP-oi3Bif3Cfcu7npJUnce8=s64","userId":"08083804319459268544"}},"colab":{"base_uri":"https://localhost:8080/","height":486}},"source":["# @title Find genes\n","\n","# This code is a work in progress. \n","# Much of it was written quickly and can be (significantly) improved.\n","# It is much slower than it needs to be and will probably get rewritten in C++ at some point.\n","\n","\n","def tokenize_aa_seq(aa_seq):\n","    \"\"\" Convert amino acid letters to integers.\"\"\"\n","    table = {\"L\": 1,\n","             \"V\": 2,\n","             \"I\": 3,\n","             \"M\": 4,\n","             \"C\": 5,\n","             \"A\": 6,\n","             \"G\": 7,\n","             \"S\": 8,\n","             \"T\": 9,\n","             \"P\": 10,\n","             \"F\": 11,\n","             \"Y\": 12,\n","             \"W\": 13,\n","             \"E\": 14,\n","             \"D\": 15,\n","             \"N\": 16,\n","             \"Q\": 17,\n","             \"K\": 18,\n","             \"R\": 19,\n","             \"H\": 20,\n","             \"*\": 0,\n","             \"X\": 0}\n","    tokenized = torch.tensor([table[aa] for aa in aa_seq])\n","    return tokenized\n","\n","\n","def get_start_codon(seq, orfcoords, strand):\n","    if strand == 1:\n","        # forward strand\n","        startcoord = orfcoords[0]\n","        return seq[startcoord-3:startcoord]\n","    else:\n","        # reverse strand\n","        startcoord = orfcoords[1]\n","        return seq[startcoord:startcoord+3].reverse_complement()\n","\n","\n","def find_ORFs(nuc_seq, minimum_length):\n","    \"\"\"find positions of all open reading frames in given reading frame\"\"\"\n","    starts = set([\"ATG\", \"GTG\", \"TTG\"]) # TODO: change this based on translation table selection\n","    stops = set([\"TAA\", \"TAG\", \"TGA\"])\n","\n","    ORF_startstop = []\n","    temp_starts = []\n","    l = len(nuc_seq)\n","    for i in range(0, l, 3): \n","        if i==0 or nuc_seq[i:i+3] in starts:\n","            temp_starts.append(i)\n","            continue\n","        if ((nuc_seq[i:i+3] in stops) or (i+3==l)) and len(temp_starts) != 0:\n","            for start in temp_starts:\n","                if (i-start >= minimum_length):\n","                    ORF_startstop.append((start, i))\n","            temp_starts = []\n","    return ORF_startstop\n","\n","\n","def get_ORF_info(seq_list):\n","    ORF_seq = []\n","    ORF_coord = []\n","    ORF_nucseq = []\n","    for i, seq in enumerate(seq_list[:]):\n","        # frame 0: starts at 0\n","        # frame 1: starts at 1\n","        # frame 2: starts at 2\n","        # frame r0: ends at 0, MAY NOT START AT THE LAST COORD DUE TO MULTIPLE OF 3 DIFFERENCES\n","        # frame r1: ends at 1\n","        # frame r2: ends at 2\n","\n","        seqstr = str(seq)\n","        seq_c = seq.complement()\n","        seqstr_c = str(seq_c)\n","        l = len(seqstr)\n","        frame_0_end = (l-0)-(l-0)%3+0\n","        frame_1_end = (l-1)-(l-1)%3+1\n","        frame_2_end = (l-2)-(l-2)%3+2\n","\n","        frame_0 = find_ORFs(seqstr[0:frame_0_end], min_orf_length)\n","        frame_1 = find_ORFs(seqstr[1:frame_1_end], min_orf_length)\n","        frame_2 = find_ORFs(seqstr[2:frame_2_end], min_orf_length)\n","\n","        frame_r0 = find_ORFs(seqstr_c[0:frame_0_end][::-1], min_orf_length)\n","        frame_r1 = find_ORFs(seqstr_c[1:frame_1_end][::-1], min_orf_length)\n","        frame_r2 = find_ORFs(seqstr_c[2:frame_2_end][::-1], min_orf_length)\n","\n","        # standardize coords\n","        ORF_0f_standard_nuccoord = [(x[0]+3, x[1]) for x in frame_0]\n","        ORF_1f_standard_nuccoord = [(x[0]+4, x[1]+1) for x in frame_1]\n","        ORF_2f_standard_nuccoord = [(x[0]+5, x[1]+2) for x in frame_2]\n","\n","        ORF_0r_standard_nuccoord = [(frame_0_end-x[1], frame_0_end-x[0]-3) for x in frame_r0]\n","        ORF_1r_standard_nuccoord = [(frame_1_end-x[1], frame_1_end-x[0]-3) for x in frame_r1]\n","        ORF_2r_standard_nuccoord = [(frame_2_end-x[1], frame_2_end-x[0]-3) for x in frame_r2]\n","\n","        # translate once per frame, then slice\n","        aa_0 = str(seq[0:frame_0_end].translate(table=11, to_stop=False))\n","        aa_1 = str(seq[1:frame_1_end].translate(table=11, to_stop=False))\n","        aa_2 = str(seq[2:frame_2_end].translate(table=11, to_stop=False))\n","        aa_r0 = str(seq_c[0:frame_0_end][::-1].translate(table=11, to_stop=False))\n","        aa_r1 = str(seq_c[1:frame_1_end][::-1].translate(table=11, to_stop=False))\n","        aa_r2 = str(seq_c[2:frame_2_end][::-1].translate(table=11, to_stop=False))\n","\n","        ORF_0f_aa = [aa_0[slice(*tuple(int(idx/3) for idx in x))][::-1] for x in frame_0] # reversed because model is trained with first amino acid directly upstream of stop codon\n","        ORF_1f_aa = [aa_1[slice(*tuple(int(idx/3) for idx in x))][::-1] for x in frame_1] \n","        ORF_2f_aa = [aa_2[slice(*tuple(int(idx/3) for idx in x))][::-1] for x in frame_2]\n","        ORF_0r_aa = [aa_r0[slice(*tuple(int(idx/3) for idx in x))][::-1] for x in frame_r0]\n","        ORF_1r_aa = [aa_r1[slice(*tuple(int(idx/3) for idx in x))][::-1] for x in frame_r1]\n","        ORF_2r_aa = [aa_r2[slice(*tuple(int(idx/3) for idx in x))][::-1] for x in frame_r2]\n","\n","        ORF_seq.append([ORF_0f_aa, ORF_1f_aa, ORF_2f_aa, \n","                        ORF_0r_aa, ORF_1r_aa, ORF_2r_aa])\n","        ORF_coord.append([ORF_0f_standard_nuccoord, ORF_1f_standard_nuccoord, ORF_2f_standard_nuccoord, \n","                          ORF_0r_standard_nuccoord, ORF_1r_standard_nuccoord, ORF_2r_standard_nuccoord])\n","        \n","        ORF_nucseq.append([str(seq[0:frame_0_end]), # all 5' to 3'\n","                           str(seq[1:frame_1_end]),\n","                           str(seq[2:frame_2_end]),\n","                           str(seq_c[0:frame_0_end][::-1]),\n","                           str(seq_c[1:frame_1_end][::-1]),\n","                           str(seq_c[2:frame_2_end][::-1])])\n","    return ORF_seq, ORF_nucseq, ORF_coord\n","\n","\n","def analyze_overlap(coords0, coords1, strand0, strand1,\n","                    unidirectional_penalty_per_base,\n","                    convergent_penalty_per_base,\n","                    divergent_penalty_per_base):\n","    overlap = coords0[1] - coords1[0] # TODO account for fully overlapped gene\n","\n","    if overlap <= 0:\n","        compatible, penalty = True, 0\n","        return compatible, penalty\n","    \n","    if overlap > max_gene_overlap:\n","        compatible, penalty = False, 0\n","        return compatible, penalty\n","\n","    # get prime locations\n","    if strand0 == 1:\n","        threeprime0 = coords0[1]\n","        fiveprime0 = coords0[0]\n","    else:\n","        threeprime0 = coords0[0]\n","        fiveprime0 = coords0[1]\n","    if strand1 == 1:\n","        threeprime1 = coords1[1]\n","        fiveprime1 = coords1[0]\n","    else:\n","        threeprime1 = coords1[0]\n","        fiveprime1 = coords1[1]\n","    \n","    # exclude ORFs in same frame sharing same stop codon\n","    if strand0 == strand1 and threeprime0 == threeprime1:\n","        compatible, penalty = False, 0\n","        return compatible, penalty\n","\n","    # unidirectional overlap\n","    if (threeprime0 < fiveprime0) == (threeprime1 < fiveprime1):\n","        compatible, penalty = True, overlap * unidirectional_penalty_per_base\n","        return compatible, penalty\n","\n","    # convergent overlap\n","    if (fiveprime0 < threeprime1 <= threeprime0) or (fiveprime1 < threeprime0 <= threeprime1):\n","        compatible, penalty = True, overlap * convergent_penalty_per_base\n","        return compatible, penalty\n","    \n","    # divergent overlap\n","    if (threeprime0 < fiveprime1 <= fiveprime0) or (threeprime1 < fiveprime0 <= fiveprime1):\n","        compatible, penalty = True, overlap * divergent_penalty_per_base\n","        return compatible, penalty\n","\n","\n","def predict(X):\n","    model.eval()\n","    with torch.no_grad():\n","        if torch.cuda.device_count() > 0:\n","            X_enc = F.one_hot(X, 21).permute(0,2,1).float().cuda()\n","        else:\n","            X_enc = F.one_hot(X, 21).permute(0,2,1).float()\n","        probs = expit(model(X_enc).cpu())\n","    return probs\n","\n","def predict_tis(X):\n","    model_tis.eval()\n","    with torch.no_grad():\n","        if torch.cuda.device_count() > 0:\n","            X_enc = F.one_hot(X, 4).permute(0,2,1).float().cuda()\n","        else:\n","            X_enc = F.one_hot(X, 4).permute(0,2,1).float()\n","        probs = expit(model_tis(X_enc).cpu())\n","    return probs\n","\n","nuc_encode = {\"A\":0,\n","              \"T\":1,\n","              \"G\":2,\n","              \"C\":3,\n","              \"N\":0,\n","              \"M\":0,\n","              \"R\":0,\n","              \"Y\":0,\n","              \"W\":0,\n","              \"K\":0}\n","              \n","start_enc = {\"ATG\":0,\n","             \"GTG\":1,\n","             \"TTG\":2}\n","\n","def tensor_to_seq(tensor):\n","    table = {0: \"X\",\n","             1: \"L\",\n","             2: \"V\",\n","             3: \"I\",\n","             4: \"M\",\n","             5: \"C\",\n","             6: \"A\",\n","             7: \"G\",\n","             8: \"S\",\n","             9: \"T\",\n","             10: \"P\",\n","             11: \"F\",\n","             12: \"Y\",\n","             13: \"W\",\n","             14: \"E\",\n","             15: \"D\",\n","             16: \"N\",\n","             17: \"Q\",\n","             18: \"K\",\n","             19: \"R\",\n","             20: \"H\"}\n","    return \"\".join([table[x] for x in tensor])\n","\n","def kmerize(seq, k):\n","    kmerset = set()\n","    for i in range(len(seq) - k + 1):\n","        kmer = tuple(seq[i: i + k].tolist())\n","        kmerset.add(kmer)\n","    return kmerset\n","\n","\n","\n","# find genes for each uploaded genome\n","GCF_list = []\n","# gene_predict_3prime_list = []\n","# gene_predict_5prime_list = []\n","# gene_predict_strand_list = []\n","contig_name_list = []\n","contig_length_list = []\n","contig_seq_list = []\n","contig_gene_coord_list = []\n","contig_gene_strand_list = []\n","\n","for genome_name in genome_dict.keys():\n","    if verbose:\n","        print(\"Reading fasta file\", str(genome_name) + \"...\\n\")\n","\n","    # read genome sequence\n","    seq_list = []\n","    contig_name_sublist = []\n","    contig_length_sublist = []\n","    if os.path.splitext(genome_name)[1].lower() == \".gz\":\n","        with gzip.open(genome_name, \"rt\") as f:\n","            for record in SeqIO.parse(f, \"fasta\"):\n","                seq_list.append(record.seq)\n","                contig_name_sublist.append(record.id)\n","                contig_length_sublist.append(len(record.seq))\n","    else:\n","        with open(genome_name, \"rt\") as f:\n","            for record in SeqIO.parse(f, \"fasta\"):\n","                seq_list.append(record.seq)\n","                contig_name_sublist.append(record.id)\n","                contig_length_sublist.append(len(record.seq))\n","    contig_name_list.append(contig_name_sublist)\n","    contig_length_list.append(contig_length_sublist)\n","    contig_seq_list.append(seq_list)\n","\n","    # get sequences and coordinates of ORFs\n","    if verbose:\n","        print(\"Finding and translating open reading frames...\\n\")\n","\n","    ORF_seq_list, ORF_nucseq_list, ORF_coord_list = get_ORF_info(seq_list)\n","\n","    # combine ORFs to submit to GPU in batches\n","    ORF_seq_combine = []\n","    for i, contig in enumerate(ORF_seq_list):\n","        for j, frame in enumerate(contig):\n","            for k, coord in enumerate(frame):\n","                ORF_seq_combine.append(coord)\n","\n","    # encode amino acids as integers\n","    if verbose:\n","        print(\"Encoding amino acids...\\n\")\n","    ORF_seq_enc = [tokenize_aa_seq(x) for x in ORF_seq_combine]\n","\n","    # seengene check\n","    if filter_kmer:\n","        if verbose:\n","            print(\"Applying kmer prefilter...\\n\")\n","        seengene = []\n","        for s in ORF_seq_enc:\n","            kmerset = kmerize(s, k_seengene)\n","            s = [x in aa_kmer_set for x in kmerset]\n","            seen = np.sum(s) >= multimer_threshold\n","\n","            seengene.append(seen)\n","\n","\n","    # score\n","    if verbose:\n","        print(\"Scoring ORFs with temporal convolutional network...\\n\")\n","\n","    # sort by length to minimize impact of batch padding \n","    ORF_lengths = np.asarray([len(x) for x in ORF_seq_enc])\n","    length_idx = np.argsort(ORF_lengths)\n","    ORF_seq_sorted = [ORF_seq_enc[i] for i in length_idx]\n","\n","    # pad to allow creation of batch matrix\n","    prob_list = []\n","    for i in tqdm(range(0, len(ORF_seq_sorted), gene_batch_size), unit=\" batch\"):\n","        batch = ORF_seq_sorted[i:i+gene_batch_size]\n","        seq_lengths = torch.LongTensor(list(map(len, batch)))\n","        seq_tensor = torch.zeros((len(batch), seq_lengths.max())).long()\n","\n","        for idx, (seq, seqlen) in enumerate(zip(batch, seq_lengths)):\n","            seq_tensor[idx, :seqlen] = torch.LongTensor(seq)\n","\n","        pred_all = predict(seq_tensor)\n","\n","        pred = []\n","        for j, length in enumerate(seq_lengths):\n","            # subseq = pred_all[j, 0, 30:int(length):1] # TODO catch prediction if 30 is too big for non-default min orf length\n","            subseq = pred_all[j, 0, 0:int(length)]\n","            predprob = float(expit(torch.mean(logit(subseq))))\n","            pred.append(predprob)\n","        \n","        prob_list.extend(pred)\n","    prob_arr = np.asarray(prob_list, dtype=float)\n","\n","    # unsort\n","    unsort_idx = np.argsort(length_idx)\n","    ORF_prob = prob_arr[unsort_idx]\n","\n","    # recombine ORFs\n","    idx = 0\n","    ORF_gene_score = copy.deepcopy(ORF_coord_list) # fill coord matrix with scores\n","    for i, contig in enumerate(ORF_gene_score):\n","        for j, frame in enumerate(contig):\n","            for k, coord in enumerate(frame):\n","                ORF_gene_score[i][j][k] = float(ORF_prob[idx])\n","                idx += 1\n","\n","    # create strand information\n","    ORF_strand_flat = []\n","    for i, seq in enumerate(ORF_seq_list):\n","        if not any(seq):\n","            ORF_strand_flat.append([])\n","            continue\n","        n_forward = len(seq[0]) + len(seq[1]) + len(seq[2])\n","        n_reverse = len(seq[3]) + len(seq[4]) + len(seq[5])\n","        ORF_allframe_strand = [1]*n_forward + [-1]*n_reverse\n","        ORF_strand_flat.append(ORF_allframe_strand)\n","\n","    # flatten coords within contigs\n","    ORF_coord_flat = [[item for sublist in x for item in sublist] for x in ORF_coord_list]\n","\n","    # get ORF lengths\n","    ORF_length_flat = [[coords[1]-coords[0] for coords in x] for x in ORF_coord_flat]\n","    \n","    if verbose:\n","        print(\"Scoring translation initiation sites...\\n\")\n","\n","    # extract nucleotide sequence surrounding potential start codons\n","    ORF_TIS_seq = copy.deepcopy(ORF_coord_list)\n","    ORF_start_codon = copy.deepcopy(ORF_coord_list)\n","\n","    for i, contig in enumerate(ORF_TIS_seq):\n","        n = 0 # count to index into flat structure # TODO make sure this works as expected\n","\n","        nucseq = ORF_nucseq_list[i][0] # easier to use coords relative to single nucseq\n","        nucseq_c = ORF_nucseq_list[i][3][::-1]\n","        contig_nuclength = len(nucseq)\n","\n","\n","        for j, frame in enumerate(contig):\n","            for k, temp in enumerate(frame):\n","                if any(temp):\n","                    coords = ORF_coord_list[i][j][k]\n","                    strand = ORF_strand_flat[i][n]\n","                    n += 1\n","                    if strand == 1:\n","                        fiveprime = coords[0]\n","                        if fiveprime >= 16 + 3: # NOTE 16 HARD CODED HERE\n","                            downstream = nucseq[fiveprime: fiveprime + 16]\n","                            upstream = nucseq[fiveprime - 16 - 3: fiveprime - 3]\n","                            start_codon = start_enc[nucseq[fiveprime-3: fiveprime]]\n","                            TIS_seq = torch.tensor([nuc_encode[c] for c in (upstream + downstream)[::-1]], dtype=int) # model scores 3' to 5' direction\n","                        else:\n","                            TIS_seq = -1 # deal with gene fragments later\n","                            start_codon = 2\n","\n","                        ORF_TIS_seq[i][j][k] = TIS_seq\n","                        ORF_start_codon[i][j][k] = start_codon\n","                        \n","                    else: # reverse strand\n","                        fiveprime = coords[1]\n","                        if contig_nuclength - fiveprime + 3 >= 16 + 3: # NOTE 16 HARD CODED HERE\n","                            downstream = nucseq_c[fiveprime - 16: fiveprime][::-1]\n","                            upstream = nucseq_c[fiveprime + 3: fiveprime + 3 + 16][::-1]\n","                            start_codon = start_enc[nucseq_c[fiveprime: fiveprime + 3][::-1]]\n","                            TIS_seq = torch.tensor([nuc_encode[c] for c in (upstream + downstream)[::-1]], dtype=int) # model scores 3' to 5' direction\n","                        else:\n","                            TIS_seq = -1 # deal with gene fragments later\n","                            start_codon = 2\n","                            \n","                        ORF_TIS_seq[i][j][k] = TIS_seq\n","                        ORF_start_codon[i][j][k] = start_codon\n","\n","    # flatten TIS for batching\n","    ORF_TIS_prob = copy.deepcopy(ORF_TIS_seq)\n","\n","    ORF_TIS_seq_flat = []\n","    ORF_TIS_seq_idx = []\n","    for i, contig in enumerate(ORF_TIS_seq):\n","        for j, frame in enumerate(contig):\n","            for k, seq in enumerate(frame):\n","                if type(seq) == int: # fragment\n","                    ORF_TIS_prob[i][j][k] = 0.5 # HOW BEST TO DEAL WITH FRAGMENT TIS?\n","                elif len(seq) != 32:\n","                    ORF_TIS_prob[i][j][k] = 0.5 \n","                else:\n","                    ORF_TIS_seq_flat.append(seq)\n","                    ORF_TIS_seq_idx.append((i, j, k))\n","\n","    # score TIS\n","    ORF_TIS_seq_all = torch.stack(ORF_TIS_seq_flat)\n","    y_pred_TIS = predict_tis(ORF_TIS_seq_all)\n","\n","    # reindex batched scores\n","    for i, prob in enumerate(y_pred_TIS):\n","        idx = ORF_TIS_seq_idx[i]\n","        ORF_TIS_prob[idx[0]][idx[1]][idx[2]] = float(prob)\n","\n","    # combine all info into single score for each ORF\n","    if filter_kmer:\n","        ORF_score_flat = []\n","        for i, contig in enumerate(ORF_gene_score):\n","            if not any(contig):\n","                ORF_score_flat.append([])\n","                continue\n","            temp = []\n","            seengene_idx = 0\n","            for j, frame in enumerate(contig):\n","                for k, geneprob in enumerate(frame):\n","                    length = ORF_coord_list[i][j][k][1] - ORF_coord_list[i][j][k][0] + 1 \n","                    TIS_prob = ORF_TIS_prob[i][j][k]\n","                    start_codon = ORF_start_codon[i][j][k]\n","                    ATG = start_codon == 0\n","                    GTG = start_codon == 1\n","                    TTG = start_codon == 2\n","\n","                    combprob =   geneprob * weight_gene_prob \\\n","                            + TIS_prob * weight_TIS_prob \\\n","                            + ATG * weight_ATG \\\n","                            + GTG * weight_TTG \\\n","                            + TTG * weight_GTG\n","                    maxprob = weight_gene_prob + weight_TIS_prob + max(weight_ATG, weight_TTG, weight_GTG)\n","                    probthresh = score_threshold * maxprob\n","                    # score = (combprob - probthresh) * length\n","                    score = (combprob - probthresh) * length  + 1e6*seengene[seengene_idx]\n","                    seengene_idx += 1\n","\n","                    temp.append(score)\n","            ORF_score_flat.append(temp)\n","\n","    else:\n","        ORF_score_flat = []\n","        for i, contig in enumerate(ORF_gene_score):\n","            if not any(contig):\n","                ORF_score_flat.append([])\n","                continue\n","            temp = []\n","            for j, frame in enumerate(contig):\n","                for k, geneprob in enumerate(frame):\n","                    length = ORF_coord_list[i][j][k][1] - ORF_coord_list[i][j][k][0] + 1 \n","                    TIS_prob = ORF_TIS_prob[i][j][k]\n","                    start_codon = ORF_start_codon[i][j][k]\n","                    ATG = start_codon == 0\n","                    GTG = start_codon == 1\n","                    TTG = start_codon == 2\n","\n","                    combprob =   geneprob * weight_gene_prob \\\n","                            + TIS_prob * weight_TIS_prob \\\n","                            + ATG * weight_ATG \\\n","                            + GTG * weight_TTG \\\n","                            + TTG * weight_GTG\n","                    maxprob = weight_gene_prob + weight_TIS_prob + max(weight_ATG, weight_TTG, weight_GTG)\n","                    probthresh = score_threshold * maxprob\n","                    score = (combprob - probthresh) * length\n","\n","                    temp.append(score)\n","            ORF_score_flat.append(temp)\n","\n","    # DAGs to maximize geneiness on each contig\n","    contig_gene_coord = []\n","    contig_gene_strand = []\n","\n","    for i, coords in enumerate(ORF_coord_flat):\n","        if verbose:\n","            print(\"Creating weighted directed acyclic graph of all ORFs on contig \" + str(i) + \"...\\n\")\n","\n","        # sort coords, lengths, strands, and scores\n","        startpos = np.array([x[0] for x in coords])\n","        sortidx = list(np.argsort(startpos))\n","\n","        coords_sorted = [coords[j] for j in sortidx]\n","\n","        lengths = ORF_length_flat[i]\n","        lengths_sorted = [lengths[j] for j in sortidx]\n","\n","        scores = ORF_score_flat[i]\n","        scores_sorted = [scores[j] for j in sortidx]\n","\n","        strands = ORF_strand_flat[i]\n","        strands_sorted = [strands[j] for j in sortidx]\n","\n","        # create DAG\n","        G = nx.DiGraph()\n","        \n","        # add null starting node\n","        G.add_node(0, coords=(-1, -1))\n","        n_connections = 0\n","        idx_offset = 1\n","        while n_connections < max_forward_connections:\n","            k = idx_offset\n","            idx_offset += 1\n","            if k > len(scores_sorted)-1: # dont try to add edge past last ORF\n","                n_connections += 1\n","                continue\n","            G.add_node(k, coords = coords_sorted[k-1])\n","            edge_weight = scores_sorted[k-1]\n","            G.add_edge(0, k, weight = edge_weight) # weight corresponds to score of gene at tip of arrow\n","            n_connections += 1\n","\n","        # add edges between compatible ORFs\n","        for j in tqdm(range(1, len(scores_sorted)-1), unit=\" ORF\"):\n","            n_connections = 0\n","            idx_offset = 1\n","\n","            G.add_node(j, coords=coords_sorted[j-1])\n","\n","            while n_connections < max_forward_connections:\n","                k = j + idx_offset\n","                idx_offset += 1\n","\n","                if k > len(scores_sorted)-1: # dont try to add edge past end of contigs\n","                    n_connections += 1\n","                    continue \n","\n","                coords0 = coords_sorted[j-1]\n","                coords1 = coords_sorted[k-1]\n","\n","                strand0 = strands_sorted[j-1]\n","                strand1 = strands_sorted[k-1]\n","\n","                compat, penalty = analyze_overlap(coords0, coords1, \n","                                                  strand0, strand1,\n","                                                  unidirectional_penalty_per_base,\n","                                                  convergent_penalty_per_base,\n","                                                  divergent_penalty_per_base)\n","\n","                if compat:\n","                    score = scores_sorted[k-1] - penalty\n","                    G.add_node(k, coords=coords_sorted[k-1])\n","                    G.add_edge(j, k, weight=score)\n","                    n_connections += 1\n","\n","        # solve for geneiest path through contig\n","        if verbose:\n","            print(\"Maximizing geneiness...\")\n","\n","        max_ORF_PATH_withnull = nx.algorithms.dag.dag_longest_path(G)\n","        max_ORF_PATH = [x-1 for x in maxfoo_ORF_PATH_withnull[1:]]\n","\n","        graph_score = [scores_sorted[j] for j in max_ORF_PATH]\n","        graph_score_total = np.sum(graph_score)\n","\n","        gene_predict_coords = [coords_sorted[j] for j in max_ORF_PATH]\n","        gene_predict_strand = [strands_sorted[j] for j in max_ORF_PATH]\n","\n","        # mmseqs filter\n","        if filter_gene_predictions:\n","            if verbose:\n","                print(\"\\nFiltering predictions with mmseqs2...\")\n","\n","            # get amino acid sequence from coherent ORFs\n","            # 3' TO 5'\n","            aa_sorted = [ORF_seq_enc[j] for j in sortidx]\n","            aa_tensor = [aa_sorted[j] for j in max_ORF_PATH]\n","            aa_seq = [tensor_to_seq([int(y) for y in x]) for x in aa_tensor]\n","\n","            # make temp dir to store mmseqs stuff\n","            finding_empty_dir = True\n","            dir_idx = 0\n","            while finding_empty_dir:\n","                dirpath = os.path.join(\"/content/mmseqs2/tmp\", str(dir_idx))\n","                if os.path.isdir(dirpath):\n","                    dir_idx += 1\n","                    continue\n","                else:\n","                    !mkdir {dirpath}\n","                    finding_empty_dir = False\n","            \n","            # mmseqs create query DB     3' to 5'\n","            query_fasta_path_35 = os.path.join(dirpath, \"candidate_genes_35.fasta\")\n","            with open(query_fasta_path_35, \"w\") as f:\n","                for i, s in enumerate(aa_seq):\n","                    f.writelines(\">\" + str(i) + \"\\n\")\n","                    f.writelines(str(s) + \"\\n\")\n","\n","            # mmseqs create query DB     5' to 3'\n","            query_fasta_path_53 = os.path.join(dirpath, \"candidate_genes_53.fasta\")\n","            with open(query_fasta_path_53, \"w\") as f:\n","                for i, s in enumerate(aa_seq):\n","                    f.writelines(\">\" + str(i) + \"\\n\")\n","                    f.writelines(str(s)[::-1] + \"\\n\")\n","\n","            query_DB_path_35 = os.path.join(dirpath, \"candidateDB_35\")\n","            !/content/mmseqs2/mmseqs/bin/mmseqs createdb {query_fasta_path_35} {query_DB_path_35}\n","            \n","            query_DB_path_53 = os.path.join(dirpath, \"candidateDB_53\")\n","            !/content/mmseqs2/mmseqs/bin/mmseqs createdb {query_fasta_path_53} {query_DB_path_53}\n","            \n","\n","            \n","            # mmseqs search\n","            results_DB_path_35 = os.path.join(dirpath, \"resultsDB_35\")\n","            !/content/mmseqs2/mmseqs/bin/mmseqs search -s 7.0 {query_DB_path_35} {genexa_DB_path} {results_DB_path_35} {dirpath}\n","\n","            # convert to readable format\n","            m8_path_genexa = os.path.join(dirpath, \"resultDB_genexa.m8\")\n","            !/content/mmseqs2/mmseqs/bin/mmseqs convertalis {query_DB_path_35} {genexa_DB_path} {results_DB_path_35} {m8_path_genexa} --format-output \"query,target,evalue,raw\"\n","\n","            # load search results\n","            mmseqs_results_genexa = pandas.read_table(m8_path_genexa, header=None, names=[\"query\", \"target\", \"evalue\", \"raw\"]).to_numpy()\n","\n","            # get minimum e-value for each hit\n","            # hit_idx = np.unique(mmseqs_results[:, 0])\n","            # min_e = [np.min(mmseqs_results[np.argwhere(mmseqs_results[:, 0] == x), 2]) for x in hit_idx]\n","            # hit_idx = [int(x) for x in hit_idx]\n","\n","            # get hits\n","            hit_idx_genexa = np.unique(mmseqs_results_genexa[:, 0]).astype(int)\n","\n","\n","\n","            # mmseqs search\n","            results_DB_path_53 = os.path.join(dirpath, \"resultsDB_53\")\n","            !/content/mmseqs2/mmseqs/bin/mmseqs search -s 7.0 {query_DB_path_53} {swissprot_DB_path} {results_DB_path_53} {dirpath}\n","            # !/content/mmseqs2/mmseqs/bin/mmseqs search -s 7.0 {query_DB_path_53} {Pfam_DB_path} {results_DB_path_53} {dirpath}\n","\n","            # convert to readable format\n","            m8_path_secondary = os.path.join(dirpath, \"resultDB_secondary.m8\")\n","            !/content/mmseqs2/mmseqs/bin/mmseqs convertalis {query_DB_path_53} {swissprot_DB_path} {results_DB_path_53} {m8_path_secondary} --format-output \"query,target,evalue,raw\"\n","            # !/content/mmseqs2/mmseqs/bin/mmseqs convertalis {query_DB_path_53} {Pfam_DB_path} {results_DB_path_53} {m8_path_secondary} --format-output \"query,target,evalue,raw\"\n","\n","            # load search results\n","            mmseqs_results_secondary = pandas.read_table(m8_path_secondary, header=None, names=[\"query\", \"target\", \"evalue\", \"raw\"]).to_numpy()\n","\n","            # get minimum e-value for each hit\n","            # hit_idx = np.unique(mmseqs_results[:, 0])\n","            # min_e = [np.min(mmseqs_results[np.argwhere(mmseqs_results[:, 0] == x), 2]) for x in hit_idx]\n","            # hit_idx = [int(x) for x in hit_idx]\n","\n","            # get hits\n","            hit_idx_secondary = np.unique(mmseqs_results_secondary[:, 0]).astype(int)\n","\n","\n","\n","\n","            # filter gene predictions, keep if mmseqs hit or high enough gene score\n","\n","            # cutoff = 170\n","            # cutoff = 230\n","            # cutoff = 260\n","            cutoff = 240\n","\n","            # cutoff = 310\n","            # cutoff = 450\n","\n","            # cutoffpath = [x for i, x in enumerate(max_ORF_PATH) if (scores_sorted[x] > cutoff or (i in hit_idx_genexa))]\n","            # cutoffpath = [x for i, x in enumerate(max_ORF_PATH) if (scores_sorted[x] > cutoff or (i in hit_idx_secondary))]\n","            cutoffpath = [x for i, x in enumerate(max_ORF_PATH) if (scores_sorted[x] > cutoff or (i in hit_idx_genexa or i in hit_idx_secondary))]\n","            gene_predict_coords = [coords_sorted[j] for j in cutoffpath]\n","            gene_predict_strand = [strands_sorted[j] for j in cutoffpath]\n","\n","            graph_score_cutoff = [scores_sorted[j] for j in cutoffpath]\n","            contig_gene_coord.append(gene_predict_coords)\n","            contig_gene_strand.append(gene_predict_strand)\n","\n","            n_genes = len(gene_predict_coords)\n","            if verbose:\n","                print(\"found\", n_genes, \"genes\\n\\n\")\n","\n","\n","        else:\n","            # just give all predictions\n","            cutoff = 0\n","            cutoffpath = [x for x in max_ORF_PATH if scores_sorted[x] > cutoff]\n","            gene_predict_coords = [coords_sorted[j] for j in cutoffpath]\n","            gene_predict_strand = [strands_sorted[j] for j in cutoffpath]\n","\n","            graph_score_cutoff = [scores_sorted[j] for j in cutoffpath]\n","            contig_gene_coord.append(gene_predict_coords)\n","            contig_gene_strand.append(gene_predict_strand)\n","\n","            n_genes = len(gene_predict_coords)\n","            if verbose:\n","                print(\"found\", n_genes, \"genes\\n\\n\")\n","    contig_gene_coord_list.append(contig_gene_coord)\n","    contig_gene_strand_list.append(contig_gene_strand)\n","\n","time.sleep(10) # colab files take a bit of time to mount\n","print(\"Done\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Reading fasta file GCF_900465355.1_Ran1-1_genomic.fna.gz...\n","\n","Finding and translating open reading frames...\n","\n","Encoding amino acids...\n","\n","Applying kmer prefilter...\n","\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-28-88f2105591d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0mseengene\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mORF_seq_enc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m             \u001b[0mkmerset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkmerize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_seengene\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maa_kmer_set\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkmerset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0mseen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mmultimer_threshold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-28-88f2105591d3>\u001b[0m in \u001b[0;36mkmerize\u001b[0;34m(seq, k)\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0mkmerset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m         \u001b[0mfoo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m         \u001b[0mkmerset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfoo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mkmerset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"M3_sRPUzDfkX","colab_type":"code","cellView":"form","colab":{}},"source":["# @title Download genome annotation (you may need to rerun this cell and/or allow multiple downloads in browser)\n","# TODO support different output formats\n","\n","def write_GFF(start, end, contig, strand, contig_name_all, contig_length_all, contig_seq_all, GFF_path_out):\n","    # writes to same format as Prokka GFF\n","    bases_per_line = 60\n","    with open(GFF_path_out, \"wt\") as f:\n","        # header\n","        f.writelines([\"##gff-version 3\\n\"])\n","\n","        # contig names and lengths\n","        datalines = [\" \".join([\"##sequence-region\", \n","                               str(contig_name_all[i]), \n","                               \"1\", \n","                               str(contig_length_all[i]), \n","                               \"\\n\"]) for i in range(len(contig_name_all))]\n","        f.writelines(datalines)\n","\n","        # CDS features\n","        datalines = [\"\\t\".join([contig[i],\n","                                \"FrodoM\",\n","                                \"CDS\",\n","                                str(int(start[i]) + 1), # off by one here?\n","                                end[i],\n","                                \".\", # TODO: replace . with gene score\n","                                strand[i],\n","                                \"0\",\n","                                \"inference=ab initio prediction:FrodoM;product=hypothetical protein\"\n","                                \"\\n\"]) for i in range(len(start))]\n","        f.writelines(datalines)\n","\n","        # contig sequences\n","        f.writelines([\"##FASTA\", \"\\n\"])\n","        for i, name in enumerate(contig_name_all):\n","            f.writelines([\">\", str(name), \"\\n\"])\n","            bases_per_line = 60\n","            seq = contig_seq_all[i]\n","            datalines = [str(seq[j:j+bases_per_line])+\"\\n\" for j in range(0, len(seq), bases_per_line)]\n","            f.writelines(datalines)\n","\n","fasta_names = list(genome_dict.keys())\n","gff_names = [str(x) + \"__.gff\" for x in fasta_names] # simpler than removing all combinations of fasta and gz from the end\n","\n","for genome_idx, gff in enumerate(gff_names):\n","    # combine all info for gene predictions\n","    contig_gene_start_flat = []\n","    contig_gene_end_flat = []\n","    contig_gene_strand_flat = []\n","    contig_gene_contig_flat = []\n","    try:\n","        for i, contig_gene_coord in enumerate(contig_gene_coord_list[genome_idx]): # TODO get rid of jenky nested lists\n","            # if any(contig_gene_coord):\n","            for k, coord in enumerate(contig_gene_coord):\n","                start = str(coord[0] - 3)\n","                end = str(coord[1] + 3)\n","                strandnum = contig_gene_strand_list[genome_idx][i][k]\n","                if strandnum == 1:\n","                    strand = \"+\"\n","                else:\n","                    strand = \"-\"\n","                contig = str(contig_name_list[genome_idx][i])\n","\n","                contig_gene_start_flat.append(start)\n","                contig_gene_end_flat.append(end)\n","                contig_gene_strand_flat.append(strand)\n","                contig_gene_contig_flat.append(contig)\n","\n","        write_GFF(contig_gene_start_flat, contig_gene_end_flat, contig_gene_contig_flat, contig_gene_strand_flat, \n","                contig_name_list[genome_idx], contig_length_list[genome_idx], contig_seq_list[genome_idx], gff)\n","    except:\n","        print(\"Could not generate \", gff)\n","\n","for gff in gff_names:\n","    try:\n","        files.download(gff)\n","    except:\n","        print(\"Could not download \", gff)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4D-TsN2GZTFj","colab_type":"text"},"source":["# MIT License\n"," Copyright (c) 2020 Markus J. Sommer\n","\n","Permission is hereby granted, free of charge, to any person obtaining a copy\n","of this software and associated documentation files (the \"Software\"), to deal\n","in the Software without restriction, including without limitation the rights\n","to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n","copies of the Software, and to permit persons to whom the Software is\n","furnished to do so, subject to the following conditions:\n","\n","The above copyright notice and this permission notice shall be included in all\n","copies or substantial portions of the Software.\n","\n","THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n","IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n","FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n","AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n","LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n","OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n","SOFTWARE."]}]}