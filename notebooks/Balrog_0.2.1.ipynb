{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Balrog_0.2.1.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm","mount_file_id":"1rAQd-UsKhliEHw_tDMGv2a_UMS4iPA3V","authorship_tag":"ABX9TyMYkSVYZr+5xeTM+NeVV9t4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"6SYiIHRhZM-m","colab_type":"text"},"source":["# Google Colab Intro\n","#### This notebook downloads data and performs computations. These computations are made significantly faster with the use of a GPU, provided free by Google as part of Colab.\n","\n","#### Press the play button on the left side of each cell to run it. Alternatively, hold shift or ctrl and press enter to run cells.\n","#### Double click the top of a cell to inspect the code inside and change things.\n","#### Have fun!\n","\n","#### (this project is meant to be a proof of concept for a different approach to finding genes, not a drop in replacement for a well-optimized gene finder. A faster C++ version will probably be released at some point if it seems like that would be useful)"]},{"cell_type":"markdown","metadata":{"id":"aEszqvakZN9C","colab_type":"text"},"source":["# Setup"]},{"cell_type":"code","metadata":{"id":"VMJQa6JAXDf_","colab_type":"code","cellView":"form","outputId":"e8324dc5-64d1-48d9-ec68-90de6bed88fa","executionInfo":{"status":"ok","timestamp":1591991233093,"user_tz":240,"elapsed":5680,"user":{"displayName":"Markus Sommer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXujbpCzD6oVvcRIT5EP-oi3Bif3Cfcu7npJUnce8=s64","userId":"08083804319459268544"}},"colab":{"base_uri":"https://localhost:8080/","height":136}},"source":["# @title Install dependencies\n","!pip install biopython\n","!pip install torch\n","print(\"\\nDone\")"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: biopython in /usr/local/lib/python3.6/dist-packages (1.77)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from biopython) (1.18.5)\n","Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.5.0+cu101)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch) (0.16.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.18.5)\n","\n","Done\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pe1PHlcjeHS8","colab_type":"code","cellView":"form","outputId":"febe76f9-c878-4be1-df8a-3ca92e9e8018","executionInfo":{"status":"ok","timestamp":1591991233743,"user_tz":240,"elapsed":5843,"user":{"displayName":"Markus Sommer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXujbpCzD6oVvcRIT5EP-oi3Bif3Cfcu7npJUnce8=s64","userId":"08083804319459268544"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# @title Import python packages\n","import os\n","import gzip\n","import copy\n","import time\n","import pandas\n","import pickle\n","import numpy as np\n","from tqdm.auto import tqdm\n","from Bio import SeqIO\n","from scipy.special import expit\n","from scipy.special import logit\n","import networkx as nx\n","from multiprocessing import Pool\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.nn.utils import weight_norm\n","\n","print(\"Done\")"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Done\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"usWmfqJNhM2X","colab_type":"code","cellView":"form","outputId":"77577c00-5ad5-4f8e-8551-111029836bdd","executionInfo":{"status":"ok","timestamp":1591991233745,"user_tz":240,"elapsed":5681,"user":{"displayName":"Markus Sommer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXujbpCzD6oVvcRIT5EP-oi3Bif3Cfcu7npJUnce8=s64","userId":"08083804319459268544"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# @title Set parameters (double click here to change defaults)\n","\"\"\" Print what the program is doing.\"\"\"\n","verbose = True\n","\n","\"\"\" Maximum ORF (open reading frame) overlap length in nucleotides.\"\"\"\n","max_gene_overlap = 60\n","\n","\"\"\" Minimum ORF length in nucleotides.\"\"\"\n","min_orf_length = 100\n","\n","\"\"\" Use mmseqs2 and a gene score cutoff to remove most false positive predictions.\"\"\"\n","filter_gene_predictions = True\n","\n","\"\"\" Use kmer prefilter to increase gene sensitivity. \n","May not play nice with high GC genomes.\"\"\"\n","filter_kmer = True\n","\n","\"\"\" Nucleotide to amino acid translation table. 11 for most bacteria/archaea.\n","4 for Mycoplasma/Spiroplasma. Can be 1 to 25.\"\"\"\n","translation_table = 11\n","\n","\"\"\" Maximum number of forward connections in the directed acyclic graph used to\n","find a set of coherent genes in each genome.\n","Higher values will slow execution time but may slightly increase performace.\n","Recommended range 30 to 100.\"\"\"\n","max_forward_connections = 50\n","\n","\"\"\" Batch size for the temporal convolutional network used to score genes.\n","Small batches and big batches slow down the model. Very big batches may crash the \n","GPU. \"\"\"\n","gene_batch_size = 3000\n","\n","\"\"\" Where the pre-trained gene model should be saved.\"\"\"\n","model_dir = \"/home\"\n","\n","\n","\"\"\" All following are internal parameters. Change at your own risk.\"\"\"\n","weight_gene_prob = 0.9746869839852076 \n","weight_TIS_prob = 0.25380288790532707 \n","score_threshold = 0.47256101519707244\n","weight_ATG = 0.84249804151264 \n","weight_GTG = 0.7083689705744909\n","weight_TTG = 0.7512400826652517 \n","unidirectional_penalty_per_base = 3.895921717182765 # 3' 5' overlap\n","convergent_penalty_per_base = 4.603432608883688 # 3' 3' overlap\n","divergent_penalty_per_base = 3.3830814940689975 # 5' 5' overlap\n","\n","k_seengene = 10\n","multimer_threshold = 2\n","\n","\n","# weight_gene_prob = 0.9746869839852076 \n","# weight_TIS_prob = 0.25380288790532707 \n","# score_threshold = 0.47256101519707244\n","# weight_ATG = 0.84\n","# weight_GTG = 0.14\n","# weight_TTG = 0.03 \n","# unidirectional_penalty_per_base = 3 # 3' 5' overlap\n","# convergent_penalty_per_base = 3 # 3' 3' overlap\n","# divergent_penalty_per_base = 5 # 5' 5' overlap\n","\n","# weight_gene_prob = 0.9578349986086553 \n","# weight_TIS_prob = 0.5144895885507309 \n","# score_threshold = 0.18612804507042569\n","# weight_ATG = 0.6958167545680435 \n","# weight_GTG = 0.5112666591536028\n","# weight_TTG = 0.5372931869382979 \n","# unidirectional_penalty_per_base = 2.7082978223323337 # 3' 5' overlap\n","# convergent_penalty_per_base = 9.28139793016752 # 3' 3' overlap\n","# divergent_penalty_per_base = 0.7174449102593538 # 5' 5' overlap\n","\n","print(\"Done\")"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Done\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"idOvBwhe0NtP","colab_type":"code","cellView":"form","outputId":"67631103-ba3b-40d3-b42f-6123da2b670f","executionInfo":{"status":"ok","timestamp":1591991244298,"user_tz":240,"elapsed":16090,"user":{"displayName":"Markus Sommer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXujbpCzD6oVvcRIT5EP-oi3Bif3Cfcu7npJUnce8=s64","userId":"08083804319459268544"}},"colab":{"base_uri":"https://localhost:8080/","height":102}},"source":["# @title Load pre-trained gene and translation initiation site models\n","\n","\"\"\" if you're interested in the inner workings of the \n","temporal convolutional network, see hubconf.py in the Github repo below.\"\"\"\n","\n","repo = \"Markusjsommer/Balrog_deployment_test\"\n","\n","torch.hub.set_dir(model_dir)\n","if torch.cuda.device_count() > 0:\n","    print(\"GPU detected...\")\n","    model = torch.hub.load(repo, \"geneTCN\", force_reload=True).cuda()\n","    model_tis = torch.hub.load(repo, \"tisTCN\", force_reload=False).cuda()\n","    time.sleep(0.5)\n","    print(\"\\nDone\")\n","else:\n","    print(\"No GPU detected, using CPU...\")\n","    model = torch.hub.load(repo, \"geneTCN\", force_reload=True)\n","    model_tis = torch.hub.load(repo, \"tisTCN\", force_reload=False)\n","    time.sleep(0.5)\n","    print(\"\\nDone\")"],"execution_count":4,"outputs":[{"output_type":"stream","text":["GPU detected...\n"],"name":"stdout"},{"output_type":"stream","text":["Downloading: \"https://github.com/Markusjsommer/Balrog_deployment_test/archive/master.zip\" to /home/master.zip\n","Using cache found in /home/Markusjsommer_Balrog_deployment_test_master\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Done\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wQMPFNbdk8vv","colab_type":"code","cellView":"form","outputId":"5f4e9ae5-6261-4e93-c1e2-4ddfdec4342c","executionInfo":{"status":"ok","timestamp":1591991249649,"user_tz":240,"elapsed":21315,"user":{"displayName":"Markus Sommer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXujbpCzD6oVvcRIT5EP-oi3Bif3Cfcu7npJUnce8=s64","userId":"08083804319459268544"}},"colab":{"base_uri":"https://localhost:8080/","height":102}},"source":["# @title Prepare kmer-based prefilter\n","if filter_kmer:\n","    # decompress kmer filter\n","    seengene_dir = \"/content/kmerfilter/\"\n","    !mkdir {seengene_dir}\n","    %cd {seengene_dir}\n","    !tar -xvzf /home/Markusjsommer_Balrog_deployment_test_master/kmer_filter/genexa_10mer_thresh2_minusARF_all.tar.gz\n","    genexa_kmer_path = os.path.join(seengene_dir, \"10mer_thresh2_minusARF_all.pkl\")\n","\n","    # load kmer filter\n","    with open(genexa_kmer_path, \"rb\") as f:\n","        aa_kmer_set = pickle.load(f)\n","\n","print(\"\\nDone\")"],"execution_count":5,"outputs":[{"output_type":"stream","text":["mkdir: cannot create directory ‘/content/kmerfilter/’: File exists\n","/content/kmerfilter\n","10mer_thresh2_minusARF_all.pkl\n","\n","Done\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"p3jzwdcGp7XN","colab_type":"code","cellView":"form","outputId":"f56ce25e-3405-4286-d6ff-4f2576e70b4f","executionInfo":{"status":"ok","timestamp":1591991322336,"user_tz":240,"elapsed":93869,"user":{"displayName":"Markus Sommer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXujbpCzD6oVvcRIT5EP-oi3Bif3Cfcu7npJUnce8=s64","userId":"08083804319459268544"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# @title Prepare mmseqs2 (will be skipped if gene prediction filter option is set to False)\n","\n","if filter_gene_predictions:\n","    ![ $(uname -m) = \"x86_64\" ] && echo \"64bit: Yes\" || echo \"64bit: No\"\n","    !grep -q sse4_1 /proc/cpuinfo && echo \"SSE4.1: Yes\" || echo \"SSE4.1: No\"\n","    !grep -q avx2 /proc/cpuinfo && echo \"AVX2: Yes\" || echo \"AVX2: No\"\n","\n","    # install\n","    !mkdir /content/mmseqs2\n","    %cd /content/mmseqs2\n","    !wget https://mmseqs.com/latest/mmseqs-linux-avx2.tar.gz\n","    !tar xvzf mmseqs-linux-avx2.tar.gz\n","\n","    # decompress fasta\n","    !mkdir /content/mmseqs2/genexa\n","    %cd /content/mmseqs2/genexa\n","    !!tar -xvzf /home/Markusjsommer_Balrog_deployment_test_master/protein_filter/genexa_genes.tar.gz\n","    genexa_fasta_path = \"/content/mmseqs2/genexa/genexa_genes.fasta\"\n","\n","    # create DB\n","    genexa_DB_path = \"/content/mmseqs2/genexa/genexaDB\"\n","    !/content/mmseqs2/mmseqs/bin/mmseqs createdb {genexa_fasta_path} {genexa_DB_path}\n","\n","    # build mmseqs index\n","    !mkdir /content/mmseqs2/tmp\n","    !/content/mmseqs2/mmseqs/bin/mmseqs createindex {genexa_DB_path} /content/mmseqs2/tmp\n","\n","    # download swissprot\n","    !mkdir /content/mmseqs2/swissprot\n","    !/content/mmseqs2/mmseqs/bin/mmseqs databases UniProtKB/Swiss-Prot /content/mmseqs2/swissprot/swissprotDB /content/mmseqs2/tmp\n","    swissprot_DB_path = \"/content/mmseqs2/swissprot/swissprotDB\"\n","    \n","print(\"\\nDone\")"],"execution_count":6,"outputs":[{"output_type":"stream","text":["64bit: Yes\n","SSE4.1: Yes\n","AVX2: Yes\n","mkdir: cannot create directory ‘/content/mmseqs2’: File exists\n","/content/mmseqs2\n","--2020-06-12 19:47:33--  https://mmseqs.com/latest/mmseqs-linux-avx2.tar.gz\n","Resolving mmseqs.com (mmseqs.com)... 141.5.100.26\n","Connecting to mmseqs.com (mmseqs.com)|141.5.100.26|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 26990108 (26M) [application/octet-stream]\n","Saving to: ‘mmseqs-linux-avx2.tar.gz.1’\n","\n","mmseqs-linux-avx2.t 100%[===================>]  25.74M  17.2MB/s    in 1.5s    \n","\n","2020-06-12 19:47:35 (17.2 MB/s) - ‘mmseqs-linux-avx2.tar.gz.1’ saved [26990108/26990108]\n","\n","mmseqs/\n","mmseqs/examples/\n","mmseqs/examples/QUERY.fasta\n","mmseqs/examples/DB.fasta\n","mmseqs/matrices/\n","mmseqs/matrices/PAM180.out\n","mmseqs/matrices/blosum85.out\n","mmseqs/matrices/blosum50.out\n","mmseqs/matrices/PAM20.out\n","mmseqs/matrices/PAM100.out\n","mmseqs/matrices/PAM80.out\n","mmseqs/matrices/blosum35.out\n","mmseqs/matrices/blosum70.out\n","mmseqs/matrices/PAM160.out\n","mmseqs/matrices/PAM50.out\n","mmseqs/matrices/PAM190.out\n","mmseqs/matrices/PAM110.out\n","mmseqs/matrices/blosum30.out\n","mmseqs/matrices/blosum55.out\n","mmseqs/matrices/VTML120.out\n","mmseqs/matrices/VTML160.out\n","mmseqs/matrices/PAM140.out\n","mmseqs/matrices/PAM10.out\n","mmseqs/matrices/blosum65.out\n","mmseqs/matrices/PAM150.out\n","mmseqs/matrices/PAM60.out\n","mmseqs/matrices/PAM40.out\n","mmseqs/matrices/VTML10.out\n","mmseqs/matrices/PAM120.out\n","mmseqs/matrices/PAM170.out\n","mmseqs/matrices/blosum62.out\n","mmseqs/matrices/nucleotide.out\n","mmseqs/matrices/blosum40.out\n","mmseqs/matrices/VTML40.out\n","mmseqs/matrices/blosum60.out\n","mmseqs/matrices/blosum75.out\n","mmseqs/matrices/blosum45.out\n","mmseqs/matrices/blosum100.out\n","mmseqs/matrices/PAM70.out\n","mmseqs/matrices/PAM90.out\n","mmseqs/matrices/PAM30.out\n","mmseqs/matrices/blosum95.out\n","mmseqs/matrices/VTML80.out\n","mmseqs/matrices/blosum90.out\n","mmseqs/matrices/VTML20.out\n","mmseqs/matrices/PAM130.out\n","mmseqs/matrices/blosum80.out\n","mmseqs/userguide.pdf\n","mmseqs/util/\n","mmseqs/util/bash-completion.sh\n","mmseqs/README.md\n","mmseqs/bin/\n","mmseqs/bin/mmseqs\n","mmseqs/LICENCE.md\n","mkdir: cannot create directory ‘/content/mmseqs2/genexa’: File exists\n","/content/mmseqs2/genexa\n","\u001b[33m/content/mmseqs2/genexa/genexaDB exists and will be overwritten.\n","\u001b[39mcreatedb /content/mmseqs2/genexa/genexa_genes.fasta /content/mmseqs2/genexa/genexaDB \n","\n","MMseqs Version:       \tdc054792d1b1d091380638a712ee7566aba2bb38\n","Database type         \t0\n","Shuffle input database\ttrue\n","Createdb mode         \t0\n","Write lookup file     \t1\n","Offset of numeric ids \t0\n","Compressed            \t0\n","Verbosity             \t3\n","\n","Converting sequences\n","[468338] 0s 798ms\n","Time for merging to genexaDB_h: 0h 0m 0s 169ms\n","Time for merging to genexaDB: 0h 0m 1s 392ms\n","Database type: Aminoacid\n","Time for processing: 0h 0m 3s 266ms\n","mkdir: cannot create directory ‘/content/mmseqs2/tmp’: File exists\n","createindex /content/mmseqs2/genexa/genexaDB /content/mmseqs2/tmp \n","\n","MMseqs Version:          \tdc054792d1b1d091380638a712ee7566aba2bb38\n","Seed substitution matrix \tnucl:nucleotide.out,aa:VTML80.out\n","k-mer length             \t0\n","Alphabet size            \tnucl:5,aa:21\n","Compositional bias       \t1\n","Max sequence length      \t65535\n","Max results per query    \t300\n","Mask residues            \t1\n","Mask lower case residues \t0\n","Spaced k-mers            \t1\n","Spaced k-mer pattern     \t\n","Sensitivity              \t7.5\n","k-score                  \t0\n","Check compatible         \t0\n","Search type              \t0\n","Split database           \t0\n","Split memory limit       \t0\n","Verbosity                \t3\n","Threads                  \t4\n","Min codons in orf        \t30\n","Max codons in length     \t32734\n","Max orf gaps             \t2147483647\n","Contig start mode        \t2\n","Contig end mode          \t2\n","Orf start mode           \t1\n","Forward frames           \t1,2,3\n","Reverse frames           \t1,2,3\n","Translation table        \t1\n","Translate orf            \t0\n","Use all table starts     \tfalse\n","Offset of numeric ids    \t0\n","Create lookup            \t0\n","Compressed               \t0\n","Add orf stop             \tfalse\n","Overlap between sequences\t0\n","Sequence split mode      \t1\n","Strand selection         \t1\n","Remove temporary files   \tfalse\n","\n","createindex /content/mmseqs2/genexa/genexaDB /content/mmseqs2/tmp \n","\n","MMseqs Version:          \tdc054792d1b1d091380638a712ee7566aba2bb38\n","Seed substitution matrix \tnucl:nucleotide.out,aa:VTML80.out\n","k-mer length             \t0\n","Alphabet size            \tnucl:5,aa:21\n","Compositional bias       \t1\n","Max sequence length      \t65535\n","Max results per query    \t300\n","Mask residues            \t1\n","Mask lower case residues \t0\n","Spaced k-mers            \t1\n","Spaced k-mer pattern     \t\n","Sensitivity              \t7.5\n","k-score                  \t0\n","Check compatible         \t0\n","Search type              \t0\n","Split database           \t0\n","Split memory limit       \t0\n","Verbosity                \t3\n","Threads                  \t4\n","Min codons in orf        \t30\n","Max codons in length     \t32734\n","Max orf gaps             \t2147483647\n","Contig start mode        \t2\n","Contig end mode          \t2\n","Orf start mode           \t1\n","Forward frames           \t1,2,3\n","Reverse frames           \t1,2,3\n","Translation table        \t1\n","Translate orf            \t0\n","Use all table starts     \tfalse\n","Offset of numeric ids    \t0\n","Create lookup            \t0\n","Compressed               \t0\n","Add orf stop             \tfalse\n","Overlap between sequences\t0\n","Sequence split mode      \t1\n","Strand selection         \t1\n","Remove temporary files   \tfalse\n","\n","indexdb /content/mmseqs2/genexa/genexaDB /content/mmseqs2/genexa/genexaDB --seed-sub-mat nucl:nucleotide.out,aa:VTML80.out -k 0 --alph-size nucl:5,aa:21 --comp-bias-corr 1 --max-seq-len 65535 --max-seqs 300 --mask 1 --mask-lower-case 0 --spaced-kmer-mode 1 -s 7.5 --k-score 0 --check-compatible 0 --search-type 0 --split 0 --split-memory-limit 0 -v 3 --threads 4 \n","\n","Estimated memory consumption: 2G\n","Write VERSION (0)\n","Write META (1)\n","Write SCOREMATRIX3MER (4)\n","Write SCOREMATRIX2MER (3)\n","Write SCOREMATRIXNAME (2)\n","Write SPACEDPATTERN (23)\n","Write DBR1INDEX (5)\n","Write DBR1DATA (6)\n","Write HDR1INDEX (18)\n","Write HDR1DATA (19)\n","Write GENERATOR (22)\n","Index table: counting k-mers\n","[=================================================================] 100.00% 468.35K 23s 114ms\n","Index table: Masked residues: 931982\n","Index table: fill\n","[=================================================================] 100.00% 468.35K 16s 701ms\n","Index statistics\n","Entries:          155110361\n","DB size:          1375 MB\n","Avg k-mer size:   2.423599\n","Top 10 k-mers\n","    TSGGGV\t2599\n","    RAARQG\t2269\n","    TSGGGI\t1980\n","    AVQQSL\t1945\n","    RLTKGS\t1733\n","    TTGGGV\t1443\n","    LAAAQQ\t896\n","    IARQGS\t831\n","    ALREVV\t810\n","    TSGGGT\t772\n","Write ENTRIES (9)\n","Write ENTRIESOFFSETS (10)\n","Write SEQINDEXDATASIZE (15)\n","Write SEQINDEXSEQOFFSET (16)\n","Write SEQINDEXDATA (14)\n","Write ENTRIESNUM (12)\n","Write SEQCOUNT (13)\n","Time for merging to genexaDB.idx: 0h 0m 0s 1ms\n","Time for processing: 0h 0m 49s 536ms\n","mkdir: cannot create directory ‘/content/mmseqs2/swissprot’: File exists\n","\u001b[33m/content/mmseqs2/swissprot/swissprotDB exists and will be overwritten.\n","\u001b[39mdatabases UniProtKB/Swiss-Prot /content/mmseqs2/swissprot/swissprotDB /content/mmseqs2/tmp \n","\n","MMseqs Version:              \tdc054792d1b1d091380638a712ee7566aba2bb38\n","Force restart with latest tmp\tfalse\n","Remove temporary files       \tfalse\n","Compressed                   \t0\n","Threads                      \t4\n","Verbosity                    \t3\n","\n","  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100   151  100   151    0     0    328      0 --:--:-- --:--:-- --:--:--   328\n","  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100 85.1M  100 85.1M    0     0  13.1M      0  0:00:06  0:00:06 --:--:-- 20.3M\n","\n","Done\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"1Ea6jrhpfF4y","colab_type":"text"},"source":["# Gene Prediction"]},{"cell_type":"code","metadata":{"id":"uh274cXnWlva","colab_type":"code","cellView":"form","outputId":"426a4cd0-138e-46d5-d498-2afb6c1307ea","executionInfo":{"status":"ok","timestamp":1591991095265,"user_tz":240,"elapsed":12692,"user":{"displayName":"Markus Sommer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXujbpCzD6oVvcRIT5EP-oi3Bif3Cfcu7npJUnce8=s64","userId":"08083804319459268544"}},"colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":74}},"source":["# @title Upload bacterial genomes as FASTA or gzipped FASTA.\n","from google.colab import files\n","genome_dict = files.upload()"],"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-3cb2bbbe-2b9a-4439-a36b-dc68a6747c37\" name=\"files[]\" multiple disabled />\n","     <output id=\"result-3cb2bbbe-2b9a-4439-a36b-dc68a6747c37\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Saving GCF_000005845.2_ASM584v2_genomic.fna.gz to GCF_000005845.2_ASM584v2_genomic.fna (1).gz\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NC4llyrGWIuK","colab_type":"code","cellView":"both","outputId":"329a4af7-ef75-45a0-85ce-18a16135f09a","executionInfo":{"status":"error","timestamp":1591066123122,"user_tz":240,"elapsed":18178,"user":{"displayName":"Markus Sommer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXujbpCzD6oVvcRIT5EP-oi3Bif3Cfcu7npJUnce8=s64","userId":"08083804319459268544"}},"colab":{"base_uri":"https://localhost:8080/","height":153}},"source":["# @title Find genes\n","\n","# This code is a work in progress. \n","# Much of it was written quickly and can be (significantly) improved.\n","# It is much slower than it needs to be and will probably get rewritten in C++ at some point.\n","\n","\n","def tokenize_aa_seq(aa_seq):\n","    \"\"\" Convert amino acid letters to integers.\"\"\"\n","    table = {\"L\": 1,\n","             \"V\": 2,\n","             \"I\": 3,\n","             \"M\": 4,\n","             \"C\": 5,\n","             \"A\": 6,\n","             \"G\": 7,\n","             \"S\": 8,\n","             \"T\": 9,\n","             \"P\": 10,\n","             \"F\": 11,\n","             \"Y\": 12,\n","             \"W\": 13,\n","             \"E\": 14,\n","             \"D\": 15,\n","             \"N\": 16,\n","             \"Q\": 17,\n","             \"K\": 18,\n","             \"R\": 19,\n","             \"H\": 20,\n","             \"*\": 0,\n","             \"X\": 0}\n","    tokenized = torch.tensor([table[aa] for aa in aa_seq])\n","    return tokenized\n","\n","\n","def get_start_codon(seq, orfcoords, strand):\n","    if strand == 1:\n","        # forward strand\n","        startcoord = orfcoords[0]\n","        return seq[startcoord-3:startcoord]\n","    else:\n","        # reverse strand\n","        startcoord = orfcoords[1]\n","        return seq[startcoord:startcoord+3].reverse_complement()\n","\n","\n","def find_ORFs(nuc_seq, minimum_length):\n","    \"\"\"find positions of all open reading frames in given reading frame\"\"\"\n","    starts = set([\"ATG\", \"GTG\", \"TTG\"]) # TODO: change this based on translation table selection\n","    stops = set([\"TAA\", \"TAG\", \"TGA\"])\n","\n","    ORF_startstop = []\n","    temp_starts = []\n","    l = len(nuc_seq)\n","    for i in range(0, l, 3): \n","        if i==0 or nuc_seq[i:i+3] in starts:\n","            temp_starts.append(i)\n","            continue\n","        if ((nuc_seq[i:i+3] in stops) or (i+3==l)) and len(temp_starts) != 0:\n","            for start in temp_starts:\n","                if (i-start >= minimum_length):\n","                    ORF_startstop.append((start, i))\n","            temp_starts = []\n","    return ORF_startstop\n","\n","\n","def get_ORF_info(seq_list):\n","    ORF_seq = []\n","    ORF_coord = []\n","    ORF_nucseq = []\n","    for i, seq in enumerate(seq_list[:]):\n","        # frame 0: starts at 0\n","        # frame 1: starts at 1\n","        # frame 2: starts at 2\n","        # frame r0: ends at 0, MAY NOT START AT THE LAST COORD DUE TO MULTIPLE OF 3 DIFFERENCES\n","        # frame r1: ends at 1\n","        # frame r2: ends at 2\n","\n","        seqstr = str(seq)\n","        seq_c = seq.complement()\n","        seqstr_c = str(seq_c)\n","        l = len(seqstr)\n","        frame_0_end = (l-0)-(l-0)%3+0\n","        frame_1_end = (l-1)-(l-1)%3+1\n","        frame_2_end = (l-2)-(l-2)%3+2\n","\n","        frame_0 = find_ORFs(seqstr[0:frame_0_end], min_orf_length)\n","        frame_1 = find_ORFs(seqstr[1:frame_1_end], min_orf_length)\n","        frame_2 = find_ORFs(seqstr[2:frame_2_end], min_orf_length)\n","\n","        frame_r0 = find_ORFs(seqstr_c[0:frame_0_end][::-1], min_orf_length)\n","        frame_r1 = find_ORFs(seqstr_c[1:frame_1_end][::-1], min_orf_length)\n","        frame_r2 = find_ORFs(seqstr_c[2:frame_2_end][::-1], min_orf_length)\n","\n","        # standardize coords\n","        ORF_0f_standard_nuccoord = [(x[0]+3, x[1]) for x in frame_0]\n","        ORF_1f_standard_nuccoord = [(x[0]+4, x[1]+1) for x in frame_1]\n","        ORF_2f_standard_nuccoord = [(x[0]+5, x[1]+2) for x in frame_2]\n","\n","        ORF_0r_standard_nuccoord = [(frame_0_end-x[1], frame_0_end-x[0]-3) for x in frame_r0]\n","        ORF_1r_standard_nuccoord = [(frame_1_end-x[1], frame_1_end-x[0]-3) for x in frame_r1]\n","        ORF_2r_standard_nuccoord = [(frame_2_end-x[1], frame_2_end-x[0]-3) for x in frame_r2]\n","\n","        # translate once per frame, then slice\n","        aa_0 = str(seq[0:frame_0_end].translate(table=11, to_stop=False))\n","        aa_1 = str(seq[1:frame_1_end].translate(table=11, to_stop=False))\n","        aa_2 = str(seq[2:frame_2_end].translate(table=11, to_stop=False))\n","        aa_r0 = str(seq_c[0:frame_0_end][::-1].translate(table=11, to_stop=False))\n","        aa_r1 = str(seq_c[1:frame_1_end][::-1].translate(table=11, to_stop=False))\n","        aa_r2 = str(seq_c[2:frame_2_end][::-1].translate(table=11, to_stop=False))\n","\n","        ORF_0f_aa = [aa_0[slice(*tuple(int(idx/3) for idx in x))][::-1] for x in frame_0] # reversed because model is trained with first amino acid directly upstream of stop codon\n","        ORF_1f_aa = [aa_1[slice(*tuple(int(idx/3) for idx in x))][::-1] for x in frame_1] \n","        ORF_2f_aa = [aa_2[slice(*tuple(int(idx/3) for idx in x))][::-1] for x in frame_2]\n","        ORF_0r_aa = [aa_r0[slice(*tuple(int(idx/3) for idx in x))][::-1] for x in frame_r0]\n","        ORF_1r_aa = [aa_r1[slice(*tuple(int(idx/3) for idx in x))][::-1] for x in frame_r1]\n","        ORF_2r_aa = [aa_r2[slice(*tuple(int(idx/3) for idx in x))][::-1] for x in frame_r2]\n","\n","        ORF_seq.append([ORF_0f_aa, ORF_1f_aa, ORF_2f_aa, \n","                        ORF_0r_aa, ORF_1r_aa, ORF_2r_aa])\n","        ORF_coord.append([ORF_0f_standard_nuccoord, ORF_1f_standard_nuccoord, ORF_2f_standard_nuccoord, \n","                          ORF_0r_standard_nuccoord, ORF_1r_standard_nuccoord, ORF_2r_standard_nuccoord])\n","        \n","        ORF_nucseq.append([str(seq[0:frame_0_end]), # all 5' to 3'\n","                           str(seq[1:frame_1_end]),\n","                           str(seq[2:frame_2_end]),\n","                           str(seq_c[0:frame_0_end][::-1]),\n","                           str(seq_c[1:frame_1_end][::-1]),\n","                           str(seq_c[2:frame_2_end][::-1])])\n","    return ORF_seq, ORF_nucseq, ORF_coord\n","\n","\n","def analyze_overlap(coords0, coords1, strand0, strand1,\n","                    unidirectional_penalty_per_base,\n","                    convergent_penalty_per_base,\n","                    divergent_penalty_per_base):\n","    overlap = coords0[1] - coords1[0] # TODO account for fully overlapped gene\n","\n","    if overlap <= 0:\n","        compatible, penalty = True, 0\n","        return compatible, penalty\n","    \n","    if overlap > max_gene_overlap:\n","        compatible, penalty = False, 0\n","        return compatible, penalty\n","\n","    # get prime locations\n","    if strand0 == 1:\n","        threeprime0 = coords0[1]\n","        fiveprime0 = coords0[0]\n","    else:\n","        threeprime0 = coords0[0]\n","        fiveprime0 = coords0[1]\n","    if strand1 == 1:\n","        threeprime1 = coords1[1]\n","        fiveprime1 = coords1[0]\n","    else:\n","        threeprime1 = coords1[0]\n","        fiveprime1 = coords1[1]\n","    \n","    # exclude ORFs in same frame sharing same stop codon\n","    if strand0 == strand1 and threeprime0 == threeprime1:\n","        compatible, penalty = False, 0\n","        return compatible, penalty\n","\n","    # unidirectional overlap\n","    if (threeprime0 < fiveprime0) == (threeprime1 < fiveprime1):\n","        compatible, penalty = True, overlap * unidirectional_penalty_per_base\n","        return compatible, penalty\n","\n","    # convergent overlap\n","    if (fiveprime0 < threeprime1 <= threeprime0) or (fiveprime1 < threeprime0 <= threeprime1):\n","        compatible, penalty = True, overlap * convergent_penalty_per_base\n","        return compatible, penalty\n","    \n","    # divergent overlap\n","    if (threeprime0 < fiveprime1 <= fiveprime0) or (threeprime1 < fiveprime0 <= fiveprime1):\n","        compatible, penalty = True, overlap * divergent_penalty_per_base\n","        return compatible, penalty\n","\n","\n","def predict(X):\n","    model.eval()\n","    with torch.no_grad():\n","        if torch.cuda.device_count() > 0:\n","            X_enc = F.one_hot(X, 21).permute(0,2,1).float().cuda()\n","        else:\n","            X_enc = F.one_hot(X, 21).permute(0,2,1).float()\n","        probs = expit(model(X_enc).cpu())\n","    return probs\n","\n","def predict_tis(X):\n","    model_tis.eval()\n","    with torch.no_grad():\n","        if torch.cuda.device_count() > 0:\n","            X_enc = F.one_hot(X, 4).permute(0,2,1).float().cuda()\n","        else:\n","            X_enc = F.one_hot(X, 4).permute(0,2,1).float()\n","        probs = expit(model_tis(X_enc).cpu())\n","    return probs\n","\n","nuc_encode = {\"A\":0,\n","              \"T\":1,\n","              \"G\":2,\n","              \"C\":3,\n","              \"N\":0,\n","              \"M\":0,\n","              \"R\":0,\n","              \"Y\":0,\n","              \"W\":0,\n","              \"K\":0}\n","              \n","start_enc = {\"ATG\":0,\n","             \"GTG\":1,\n","             \"TTG\":2}\n","\n","def tensor_to_seq(tensor):\n","    table = {0: \"X\",\n","             1: \"L\",\n","             2: \"V\",\n","             3: \"I\",\n","             4: \"M\",\n","             5: \"C\",\n","             6: \"A\",\n","             7: \"G\",\n","             8: \"S\",\n","             9: \"T\",\n","             10: \"P\",\n","             11: \"F\",\n","             12: \"Y\",\n","             13: \"W\",\n","             14: \"E\",\n","             15: \"D\",\n","             16: \"N\",\n","             17: \"Q\",\n","             18: \"K\",\n","             19: \"R\",\n","             20: \"H\"}\n","    return \"\".join([table[x] for x in tensor])\n","\n","def kmerfilter(seq):\n","    kmerset = kmerize(seq, k_seengene)\n","    s = [x in aa_kmer_set for x in kmerset]\n","    seen = np.sum(s) >= multimer_threshold\n","    return seen\n","\n","def kmerize(seq, k):\n","    kmerset = set()\n","    for i in range(len(seq) - k + 1):\n","        kmer = tuple(seq[i: i + k].tolist())\n","        kmerset.add(kmer)\n","    return kmerset\n","\n","\n","\n","# find genes for each uploaded genome\n","GCF_list = []\n","contig_name_list = []\n","contig_length_list = []\n","contig_seq_list = []\n","contig_gene_coord_list = []\n","contig_gene_strand_list = []\n","\n","for genome_name in genome_dict.keys():\n","    if verbose:\n","        print(\"Reading fasta file\", str(genome_name) + \"...\\n\")\n","\n","    # read genome sequence\n","    seq_list = []\n","    contig_name_sublist = []\n","    contig_length_sublist = []\n","    if os.path.splitext(genome_name)[1].lower() == \".gz\":\n","        with gzip.open(genome_name, \"rt\") as f:\n","            for record in SeqIO.parse(f, \"fasta\"):\n","                seq_list.append(record.seq)\n","                contig_name_sublist.append(record.id)\n","                contig_length_sublist.append(len(record.seq))\n","    else:\n","        with open(genome_name, \"rt\") as f:\n","            for record in SeqIO.parse(f, \"fasta\"):\n","                seq_list.append(record.seq)\n","                contig_name_sublist.append(record.id)\n","                contig_length_sublist.append(len(record.seq))\n","    contig_name_list.append(contig_name_sublist)\n","    contig_length_list.append(contig_length_sublist)\n","    contig_seq_list.append(seq_list)\n","\n","    # get sequences and coordinates of ORFs\n","    if verbose:\n","        print(\"Finding and translating open reading frames...\\n\")\n","\n","    ORF_seq_list, ORF_nucseq_list, ORF_coord_list = get_ORF_info(seq_list)\n","\n","    # combine ORFs to submit to GPU in batches\n","    ORF_seq_combine = []\n","    for i, contig in enumerate(ORF_seq_list):\n","        for j, frame in enumerate(contig):\n","            for k, coord in enumerate(frame):\n","                ORF_seq_combine.append(coord)\n","\n","    # encode amino acids as integers\n","    if verbose:\n","        print(\"Encoding amino acids...\\n\")\n","    ORF_seq_enc = [tokenize_aa_seq(x) for x in ORF_seq_combine]\n","\n","    # seengene check\n","    if filter_kmer:\n","        if verbose:\n","            print(\"Applying kmer prefilter...\\n\")\n","        seengene = []\n","        for s in ORF_seq_enc:\n","            kmerset = kmerize(s, k_seengene)\n","            s = [x in aa_kmer_set for x in kmerset]\n","            seen = np.sum(s) >= multimer_threshold\n","\n","            seengene.append(seen)\n","        # with Pool(4) as P:\n","        #     seengene = P.map(kmerfilter, ORF_seq_enc)\n","\n","    # score\n","    if verbose:\n","        print(\"Scoring ORFs with temporal convolutional network...\\n\")\n","\n","    # sort by length to minimize impact of batch padding \n","    ORF_lengths = np.asarray([len(x) for x in ORF_seq_enc])\n","    length_idx = np.argsort(ORF_lengths)\n","    ORF_seq_sorted = [ORF_seq_enc[i] for i in length_idx]\n","\n","    # pad to allow creation of batch matrix\n","    prob_list = []\n","    for i in tqdm(range(0, len(ORF_seq_sorted), gene_batch_size), unit=\" batch\"):\n","        batch = ORF_seq_sorted[i:i+gene_batch_size]\n","        seq_lengths = torch.LongTensor(list(map(len, batch)))\n","        seq_tensor = torch.zeros((len(batch), seq_lengths.max())).long()\n","\n","        for idx, (seq, seqlen) in enumerate(zip(batch, seq_lengths)):\n","            seq_tensor[idx, :seqlen] = torch.LongTensor(seq)\n","\n","        pred_all = predict(seq_tensor)\n","\n","        pred = []\n","        for j, length in enumerate(seq_lengths):\n","            # subseq = pred_all[j, 0, 30:int(length):1] # TODO catch prediction if 30 is too big for non-default min orf length\n","            subseq = pred_all[j, 0, 0:int(length)]\n","            predprob = float(expit(torch.mean(logit(subseq))))\n","            pred.append(predprob)\n","        \n","        prob_list.extend(pred)\n","    prob_arr = np.asarray(prob_list, dtype=float)\n","\n","    # unsort\n","    unsort_idx = np.argsort(length_idx)\n","    ORF_prob = prob_arr[unsort_idx]\n","\n","    # recombine ORFs\n","    idx = 0\n","    ORF_gene_score = copy.deepcopy(ORF_coord_list) # fill coord matrix with scores\n","    for i, contig in enumerate(ORF_gene_score):\n","        for j, frame in enumerate(contig):\n","            for k, coord in enumerate(frame):\n","                ORF_gene_score[i][j][k] = float(ORF_prob[idx])\n","                idx += 1\n","\n","    # create strand information\n","    ORF_strand_flat = []\n","    for i, seq in enumerate(ORF_seq_list):\n","        if not any(seq):\n","            ORF_strand_flat.append([])\n","            continue\n","        n_forward = len(seq[0]) + len(seq[1]) + len(seq[2])\n","        n_reverse = len(seq[3]) + len(seq[4]) + len(seq[5])\n","        ORF_allframe_strand = [1]*n_forward + [-1]*n_reverse\n","        ORF_strand_flat.append(ORF_allframe_strand)\n","\n","    # flatten coords within contigs\n","    ORF_coord_flat = [[item for sublist in x for item in sublist] for x in ORF_coord_list]\n","\n","    # get ORF lengths\n","    ORF_length_flat = [[coords[1]-coords[0] for coords in x] for x in ORF_coord_flat]\n","    \n","    if verbose:\n","        print(\"Scoring translation initiation sites...\\n\")\n","\n","    # extract nucleotide sequence surrounding potential start codons\n","    ORF_TIS_seq = copy.deepcopy(ORF_coord_list)\n","    ORF_start_codon = copy.deepcopy(ORF_coord_list)\n","\n","    for i, contig in enumerate(ORF_TIS_seq):\n","        n = 0 # count to index into flat structure # TODO make sure this works as expected\n","\n","        nucseq = ORF_nucseq_list[i][0] # easier to use coords relative to single nucseq\n","        nucseq_c = ORF_nucseq_list[i][3][::-1]\n","        contig_nuclength = len(nucseq)\n","\n","\n","        for j, frame in enumerate(contig):\n","            for k, temp in enumerate(frame):\n","                if any(temp):\n","                    coords = ORF_coord_list[i][j][k]\n","                    strand = ORF_strand_flat[i][n]\n","                    n += 1\n","                    if strand == 1:\n","                        fiveprime = coords[0]\n","                        if fiveprime >= 16 + 3: # NOTE 16 HARD CODED HERE\n","                            downstream = nucseq[fiveprime: fiveprime + 16]\n","                            upstream = nucseq[fiveprime - 16 - 3: fiveprime - 3]\n","                            start_codon = start_enc[nucseq[fiveprime-3: fiveprime]]\n","                            TIS_seq = torch.tensor([nuc_encode[c] for c in (upstream + downstream)[::-1]], dtype=int) # model scores 3' to 5' direction\n","                        else:\n","                            TIS_seq = -1 # deal with gene fragments later\n","                            start_codon = 2\n","\n","                        ORF_TIS_seq[i][j][k] = TIS_seq\n","                        ORF_start_codon[i][j][k] = start_codon\n","                        \n","                    else: # reverse strand\n","                        fiveprime = coords[1]\n","                        if contig_nuclength - fiveprime + 3 >= 16 + 3: # NOTE 16 HARD CODED HERE\n","                            downstream = nucseq_c[fiveprime - 16: fiveprime][::-1]\n","                            upstream = nucseq_c[fiveprime + 3: fiveprime + 3 + 16][::-1]\n","                            start_codon = start_enc[nucseq_c[fiveprime: fiveprime + 3][::-1]]\n","                            TIS_seq = torch.tensor([nuc_encode[c] for c in (upstream + downstream)[::-1]], dtype=int) # model scores 3' to 5' direction\n","                        else:\n","                            TIS_seq = -1 # deal with gene fragments later\n","                            start_codon = 2\n","                            \n","                        ORF_TIS_seq[i][j][k] = TIS_seq\n","                        ORF_start_codon[i][j][k] = start_codon\n","\n","    # flatten TIS for batching\n","    ORF_TIS_prob = copy.deepcopy(ORF_TIS_seq)\n","\n","    ORF_TIS_seq_flat = []\n","    ORF_TIS_seq_idx = []\n","    for i, contig in enumerate(ORF_TIS_seq):\n","        for j, frame in enumerate(contig):\n","            for k, seq in enumerate(frame):\n","                if type(seq) == int: # fragment\n","                    ORF_TIS_prob[i][j][k] = 0.5 # HOW BEST TO DEAL WITH FRAGMENT TIS?\n","                elif len(seq) != 32:\n","                    ORF_TIS_prob[i][j][k] = 0.5 \n","                else:\n","                    ORF_TIS_seq_flat.append(seq)\n","                    ORF_TIS_seq_idx.append((i, j, k))\n","\n","    # score TIS\n","    ORF_TIS_seq_all = torch.stack(ORF_TIS_seq_flat)\n","    y_pred_TIS = predict_tis(ORF_TIS_seq_all)\n","\n","    # reindex batched scores\n","    for i, prob in enumerate(y_pred_TIS):\n","        idx = ORF_TIS_seq_idx[i]\n","        ORF_TIS_prob[idx[0]][idx[1]][idx[2]] = float(prob)\n","\n","    # combine all info into single score for each ORF\n","    if filter_kmer:\n","        ORF_score_flat = []\n","        for i, contig in enumerate(ORF_gene_score):\n","            if not any(contig):\n","                ORF_score_flat.append([])\n","                continue\n","            temp = []\n","            seengene_idx = 0\n","            for j, frame in enumerate(contig):\n","                for k, geneprob in enumerate(frame):\n","                    length = ORF_coord_list[i][j][k][1] - ORF_coord_list[i][j][k][0] + 1 \n","                    TIS_prob = ORF_TIS_prob[i][j][k]\n","                    start_codon = ORF_start_codon[i][j][k]\n","                    ATG = start_codon == 0\n","                    GTG = start_codon == 1\n","                    TTG = start_codon == 2\n","\n","                    combprob =   geneprob * weight_gene_prob \\\n","                            + TIS_prob * weight_TIS_prob \\\n","                            + ATG * weight_ATG \\\n","                            + GTG * weight_TTG \\\n","                            + TTG * weight_GTG\n","                    maxprob = weight_gene_prob + weight_TIS_prob + max(weight_ATG, weight_TTG, weight_GTG)\n","                    probthresh = score_threshold * maxprob\n","                    score = (combprob - probthresh) * length  + 1e6*seengene[seengene_idx]\n","                    seengene_idx += 1\n","\n","                    temp.append(score)\n","            ORF_score_flat.append(temp)\n","\n","    else:\n","        ORF_score_flat = []\n","        for i, contig in enumerate(ORF_gene_score):\n","            if not any(contig):\n","                ORF_score_flat.append([])\n","                continue\n","            temp = []\n","            for j, frame in enumerate(contig):\n","                for k, geneprob in enumerate(frame):\n","                    length = ORF_coord_list[i][j][k][1] - ORF_coord_list[i][j][k][0] + 1 \n","                    TIS_prob = ORF_TIS_prob[i][j][k]\n","                    start_codon = ORF_start_codon[i][j][k]\n","                    ATG = start_codon == 0\n","                    GTG = start_codon == 1\n","                    TTG = start_codon == 2\n","\n","                    combprob =   geneprob * weight_gene_prob \\\n","                            + TIS_prob * weight_TIS_prob \\\n","                            + ATG * weight_ATG \\\n","                            + GTG * weight_TTG \\\n","                            + TTG * weight_GTG\n","                    maxprob = weight_gene_prob + weight_TIS_prob + max(weight_ATG, weight_TTG, weight_GTG)\n","                    probthresh = score_threshold * maxprob\n","                    score = (combprob - probthresh) * length\n","\n","                    temp.append(score)\n","            ORF_score_flat.append(temp)\n","\n","    # DAGs to maximize geneiness on each contig\n","    contig_gene_coord = []\n","    contig_gene_strand = []\n","\n","    for i, coords in enumerate(ORF_coord_flat):\n","        if verbose:\n","            print(\"Creating weighted directed acyclic graph of all ORFs and subORFs on contig \" + str(i) + \"...\\n\")\n","\n","        # sort coords, lengths, strands, and scores\n","        startpos = np.array([x[0] for x in coords])\n","        sortidx = list(np.argsort(startpos))\n","\n","        coords_sorted = [coords[j] for j in sortidx]\n","\n","        lengths = ORF_length_flat[i]\n","        lengths_sorted = [lengths[j] for j in sortidx]\n","\n","        scores = ORF_score_flat[i]\n","        scores_sorted = [scores[j] for j in sortidx]\n","\n","        strands = ORF_strand_flat[i]\n","        strands_sorted = [strands[j] for j in sortidx]\n","\n","        # create DAG\n","        G = nx.DiGraph()\n","        \n","        # add null starting node\n","        G.add_node(0, coords=(-1, -1))\n","        n_connections = 0\n","        idx_offset = 1\n","        while n_connections < max_forward_connections:\n","            k = idx_offset\n","            idx_offset += 1\n","            if k > len(scores_sorted)-1: # dont try to add edge past last ORF\n","                n_connections += 1\n","                continue\n","            G.add_node(k, coords = coords_sorted[k-1])\n","            edge_weight = scores_sorted[k-1]\n","            G.add_edge(0, k, weight = edge_weight) # weight corresponds to score of gene at tip of arrow\n","            n_connections += 1\n","\n","        # add edges between compatible ORFs\n","        for j in tqdm(range(1, len(scores_sorted)-1), unit=\" ORF\"):\n","            n_connections = 0\n","            idx_offset = 1\n","\n","            G.add_node(j, coords=coords_sorted[j-1])\n","\n","            while n_connections < max_forward_connections:\n","                k = j + idx_offset\n","                idx_offset += 1\n","\n","                if k > len(scores_sorted)-1: # dont try to add edge past end of contigs\n","                    n_connections += 1\n","                    continue \n","\n","                coords0 = coords_sorted[j-1]\n","                coords1 = coords_sorted[k-1]\n","\n","                strand0 = strands_sorted[j-1]\n","                strand1 = strands_sorted[k-1]\n","\n","                compat, penalty = analyze_overlap(coords0, coords1, \n","                                                  strand0, strand1,\n","                                                  unidirectional_penalty_per_base,\n","                                                  convergent_penalty_per_base,\n","                                                  divergent_penalty_per_base)\n","\n","                if compat:\n","                    score = scores_sorted[k-1] - penalty\n","                    G.add_node(k, coords=coords_sorted[k-1])\n","                    G.add_edge(j, k, weight=score)\n","                    n_connections += 1\n","\n","        # solve for geneiest path through contig\n","        if verbose:\n","            print(\"Maximizing geneiness...\")\n","\n","        max_ORF_PATH_withnull = nx.algorithms.dag.dag_longest_path(G)\n","        max_ORF_PATH = [x-1 for x in max_ORF_PATH_withnull[1:]]\n","\n","        graph_score = [scores_sorted[j] for j in max_ORF_PATH]\n","        graph_score_total = np.sum(graph_score)\n","\n","        gene_predict_coords = [coords_sorted[j] for j in max_ORF_PATH]\n","        gene_predict_strand = [strands_sorted[j] for j in max_ORF_PATH]\n","\n","        # mmseqs filter\n","        if filter_gene_predictions:\n","            if verbose:\n","                print(\"\\nFiltering predictions with mmseqs2...\")\n","\n","            # get amino acid sequence from coherent ORFs\n","            # 3' TO 5'\n","            aa_sorted = [ORF_seq_enc[j] for j in sortidx]\n","            aa_tensor = [aa_sorted[j] for j in max_ORF_PATH]\n","            aa_seq = [tensor_to_seq([int(y) for y in x]) for x in aa_tensor]\n","\n","            # make temp dir to store mmseqs stuff\n","            finding_empty_dir = True\n","            dir_idx = 0\n","            while finding_empty_dir:\n","                dirpath = os.path.join(\"/content/mmseqs2/tmp\", str(dir_idx))\n","                if os.path.isdir(dirpath):\n","                    dir_idx += 1\n","                    continue\n","                else:\n","                    !mkdir {dirpath}\n","                    finding_empty_dir = False\n","            \n","            # mmseqs create query DB     3' to 5'\n","            query_fasta_path_35 = os.path.join(dirpath, \"candidate_genes_35.fasta\")\n","            with open(query_fasta_path_35, \"w\") as f:\n","                for i, s in enumerate(aa_seq):\n","                    f.writelines(\">\" + str(i) + \"\\n\")\n","                    f.writelines(str(s) + \"\\n\")\n","\n","            # mmseqs create query DB     5' to 3'\n","            query_fasta_path_53 = os.path.join(dirpath, \"candidate_genes_53.fasta\")\n","            with open(query_fasta_path_53, \"w\") as f:\n","                for i, s in enumerate(aa_seq):\n","                    f.writelines(\">\" + str(i) + \"\\n\")\n","                    f.writelines(str(s)[::-1] + \"\\n\")\n","\n","            query_DB_path_35 = os.path.join(dirpath, \"candidateDB_35\")\n","            !/content/mmseqs2/mmseqs/bin/mmseqs createdb {query_fasta_path_35} {query_DB_path_35}\n","            \n","            query_DB_path_53 = os.path.join(dirpath, \"candidateDB_53\")\n","            !/content/mmseqs2/mmseqs/bin/mmseqs createdb {query_fasta_path_53} {query_DB_path_53}\n","            \n","\n","            \n","            # mmseqs search\n","            results_DB_path_35 = os.path.join(dirpath, \"resultsDB_35\")\n","            !/content/mmseqs2/mmseqs/bin/mmseqs search -s 7.0 {query_DB_path_35} {genexa_DB_path} {results_DB_path_35} {dirpath}\n","\n","            # convert to readable format\n","            m8_path_genexa = os.path.join(dirpath, \"resultDB_genexa.m8\")\n","            !/content/mmseqs2/mmseqs/bin/mmseqs convertalis {query_DB_path_35} {genexa_DB_path} {results_DB_path_35} {m8_path_genexa} --format-output \"query,target,evalue,raw\"\n","\n","            # load search results\n","            mmseqs_results_genexa = pandas.read_table(m8_path_genexa, header=None, names=[\"query\", \"target\", \"evalue\", \"raw\"]).to_numpy()\n","\n","            # get hits\n","            hit_idx_genexa = np.unique(mmseqs_results_genexa[:, 0]).astype(int)\n","\n","            # mmseqs search\n","            results_DB_path_53 = os.path.join(dirpath, \"resultsDB_53\")\n","            !/content/mmseqs2/mmseqs/bin/mmseqs search -s 7.0 {query_DB_path_53} {swissprot_DB_path} {results_DB_path_53} {dirpath}\n","\n","            # convert to readable format\n","            m8_path_secondary = os.path.join(dirpath, \"resultDB_secondary.m8\")\n","            !/content/mmseqs2/mmseqs/bin/mmseqs convertalis {query_DB_path_53} {swissprot_DB_path} {results_DB_path_53} {m8_path_secondary} --format-output \"query,target,evalue,raw\"\n","\n","            # load search results\n","            mmseqs_results_secondary = pandas.read_table(m8_path_secondary, header=None, names=[\"query\", \"target\", \"evalue\", \"raw\"]).to_numpy()\n","\n","            # get hits\n","            hit_idx_secondary = np.unique(mmseqs_results_secondary[:, 0]).astype(int)\n","\n","            # filter gene predictions, keep if mmseqs hit or high enough gene score\n","            cutoff = 240\n","\n","            cutoffpath = [x for i, x in enumerate(max_ORF_PATH) if (scores_sorted[x] > cutoff or (i in hit_idx_genexa or i in hit_idx_secondary))]\n","            gene_predict_coords = [coords_sorted[j] for j in cutoffpath]\n","            gene_predict_strand = [strands_sorted[j] for j in cutoffpath]\n","\n","            graph_score_cutoff = [scores_sorted[j] for j in cutoffpath]\n","            contig_gene_coord.append(gene_predict_coords)\n","            contig_gene_strand.append(gene_predict_strand)\n","\n","            n_genes = len(gene_predict_coords)\n","            if verbose:\n","                print(\"found\", n_genes, \"genes\\n\\n\")\n","\n","\n","        else:\n","            # just give all predictions\n","            cutoff = 0\n","            cutoffpath = [x for x in max_ORF_PATH if scores_sorted[x] > cutoff]\n","            gene_predict_coords = [coords_sorted[j] for j in cutoffpath]\n","            gene_predict_strand = [strands_sorted[j] for j in cutoffpath]\n","\n","            graph_score_cutoff = [scores_sorted[j] for j in cutoffpath]\n","            contig_gene_coord.append(gene_predict_coords)\n","            contig_gene_strand.append(gene_predict_strand)\n","\n","            n_genes = len(gene_predict_coords)\n","            if verbose:\n","                print(\"found\", n_genes, \"genes\\n\\n\")\n","    contig_gene_coord_list.append(contig_gene_coord)\n","    contig_gene_strand_list.append(contig_gene_strand)\n","\n","time.sleep(5) # colab files take a bit of time to mount\n","print(\"Done\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Reading fasta file GCF_000005845.2_ASM584v2_genomic.fna.gz...\n","\n","Finding and translating open reading frames...\n","\n","Encoding amino acids...\n","\n","Applying kmer prefilter...\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"M3_sRPUzDfkX","colab_type":"code","cellView":"form","colab":{}},"source":["# @title Download genome annotation (you may need to rerun this cell and/or allow multiple downloads in browser)\n","# TODO support different output formats\n","\n","def write_GFF(start, end, contig, strand, contig_name_all, contig_length_all, contig_seq_all, GFF_path_out):\n","    # writes to same format as Prokka GFF\n","    bases_per_line = 60\n","    with open(GFF_path_out, \"wt\") as f:\n","        # header\n","        f.writelines([\"##gff-version 3\\n\"])\n","\n","        # contig names and lengths\n","        datalines = [\" \".join([\"##sequence-region\", \n","                               str(contig_name_all[i]), \n","                               \"1\", \n","                               str(contig_length_all[i]), \n","                               \"\\n\"]) for i in range(len(contig_name_all))]\n","        f.writelines(datalines)\n","\n","        # CDS features\n","        datalines = [\"\\t\".join([contig[i],\n","                                \"FrodoM\",\n","                                \"CDS\",\n","                                str(int(start[i]) + 1), # off by one here?\n","                                end[i],\n","                                \".\", # TODO: replace . with gene score\n","                                strand[i],\n","                                \"0\",\n","                                \"inference=ab initio prediction:FrodoM;product=hypothetical protein\"\n","                                \"\\n\"]) for i in range(len(start))]\n","        f.writelines(datalines)\n","\n","        # contig sequences\n","        f.writelines([\"##FASTA\", \"\\n\"])\n","        for i, name in enumerate(contig_name_all):\n","            f.writelines([\">\", str(name), \"\\n\"])\n","            bases_per_line = 60\n","            seq = contig_seq_all[i]\n","            datalines = [str(seq[j:j+bases_per_line])+\"\\n\" for j in range(0, len(seq), bases_per_line)]\n","            f.writelines(datalines)\n","\n","fasta_names = list(genome_dict.keys())\n","gff_names = [str(x) + \"__.gff\" for x in fasta_names] # simpler than removing all combinations of fasta and gz from the end\n","\n","for genome_idx, gff in enumerate(gff_names):\n","    # combine all info for gene predictions\n","    contig_gene_start_flat = []\n","    contig_gene_end_flat = []\n","    contig_gene_strand_flat = []\n","    contig_gene_contig_flat = []\n","    try:\n","        for i, contig_gene_coord in enumerate(contig_gene_coord_list[genome_idx]): # TODO get rid of jenky nested lists\n","            # if any(contig_gene_coord):\n","            for k, coord in enumerate(contig_gene_coord):\n","                start = str(coord[0] - 3)\n","                end = str(coord[1] + 3)\n","                strandnum = contig_gene_strand_list[genome_idx][i][k]\n","                if strandnum == 1:\n","                    strand = \"+\"\n","                else:\n","                    strand = \"-\"\n","                contig = str(contig_name_list[genome_idx][i])\n","\n","                contig_gene_start_flat.append(start)\n","                contig_gene_end_flat.append(end)\n","                contig_gene_strand_flat.append(strand)\n","                contig_gene_contig_flat.append(contig)\n","\n","        write_GFF(contig_gene_start_flat, contig_gene_end_flat, contig_gene_contig_flat, contig_gene_strand_flat, \n","                contig_name_list[genome_idx], contig_length_list[genome_idx], contig_seq_list[genome_idx], gff)\n","    except:\n","        print(\"Could not generate \", gff)\n","\n","for gff in gff_names:\n","    try:\n","        files.download(gff)\n","    except:\n","        print(\"Could not download \", gff)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4D-TsN2GZTFj","colab_type":"text"},"source":["# MIT License\n"," Copyright (c) 2020 Markus J. Sommer\n","\n","Permission is hereby granted, free of charge, to any person obtaining a copy\n","of this software and associated documentation files (the \"Software\"), to deal\n","in the Software without restriction, including without limitation the rights\n","to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n","copies of the Software, and to permit persons to whom the Software is\n","furnished to do so, subject to the following conditions:\n","\n","The above copyright notice and this permission notice shall be included in all\n","copies or substantial portions of the Software.\n","\n","THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n","IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n","FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n","AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n","LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n","OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n","SOFTWARE."]}]}